{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "single_cell_continuous.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9aIRaaghtOe"
      },
      "source": [
        "## Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwoRZsWohI59"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.utils import shuffle\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "import math\n",
        "import matplotlib as mpl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVcqZRjDhr2B"
      },
      "source": [
        "from tqdm import tqdm_notebook, trange\n",
        "\n",
        "def seed_everything(seed = 42): \n",
        "  random.seed(seed) \n",
        "  os.environ['PYTHONHASHSEED'] = str(seed) \n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed) \n",
        "  torch.cuda.manual_seed(seed) \n",
        "  torch.backends.cudnn.deterministic = True\n",
        "# For reproducible results\n",
        "seed_everything()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC_LhMbUhwQz"
      },
      "source": [
        "mpl.style.use('seaborn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUFIW4LSm-r2"
      },
      "source": [
        "''' using fastai models'''\n",
        "# !pip install -U fastai "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1K6fXLehyQG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEbbi9A1hzWh"
      },
      "source": [
        "%cd /content/gdrive/My Drive/seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGOw2CTYh45K"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPDF3xLYh0j3"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.data = X\n",
        "        self.target = Y\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByZDT2mwh6F4"
      },
      "source": [
        "npzfile = np.load('data/gtex/adi.npz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb7CPf8DiCEY"
      },
      "source": [
        "X, Y = npzfile['arr_0'], npzfile['arr_1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv_yCS0EkQ0U"
      },
      "source": [
        "X, Y = shuffle(X, Y, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e-RevIdiFM7"
      },
      "source": [
        "testX = X[int(len(Y)*0.8):]\n",
        "testY = Y[int(len(Y)*0.8):]\n",
        "validX = X[int(len(Y)*0.6):int(len(Y)*0.8)]\n",
        "validY = Y[int(len(Y)*0.6):int(len(Y)*0.8)]\n",
        "trainX = X[:int(len(Y)*0.6)]\n",
        "trainY = Y[:int(len(Y)*0.6)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCCN-ybriJJ3"
      },
      "source": [
        "### Convert to Torch Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfnxuDCbiLMH"
      },
      "source": [
        "train_X = torch.from_numpy(trainX)\n",
        "train_y = torch.from_numpy(trainY)\n",
        "valid_X  = torch.from_numpy(validX)\n",
        "valid_y = torch.from_numpy(validY)\n",
        "test_X = torch.from_numpy(testX)\n",
        "test_y = torch.from_numpy(testY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB79nKP-iMPH"
      },
      "source": [
        "train_dataset = MyDataset(train_X, train_y)\n",
        "valid_dataset = MyDataset(valid_X, valid_y)\n",
        "test_dataset = MyDataset(test_X, test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZdT2YjkiPGU"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNGCp8RxiPWy"
      },
      "source": [
        "def bestmodel(model_name,save_model_time,valid_loss):\n",
        "    bestloss = 10000\n",
        "    if valid_loss < bestloss :\n",
        "        bestloss = valid_loss\n",
        "        torch.save(model_name, 'model/model{save_model_time}/bestmodel.pkl'.format(save_model_time=save_model_time))\n",
        "        torch.save(model_name.state_dict(), 'model/model{save_model_time}/net_params_bestmodel.pkl'.format(save_model_time=save_model_time))\n",
        "    return True  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-9R-hNF1esi"
      },
      "source": [
        "### Mutation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKLNM3lSUqDp"
      },
      "source": [
        "def reverse(x):\n",
        "    ori = []\n",
        "    all_cap_letters = ['A', 'T', 'G', 'C'] # depends on dataset\n",
        "    all_cap_letters = ['A', 'C', 'G', 'T']\n",
        "\n",
        "    for c in range(len(x[0])):\n",
        "        for r in range(4):\n",
        "            if x[r][c] == 1:\n",
        "                ori.append(all_cap_letters[r])\n",
        "\n",
        "    return ''.join(ori)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9fIHcxW8f7t"
      },
      "source": [
        "def onehot(X):\n",
        "    X_onehot = np.zeros((4, len(X)), dtype=np.float32)\n",
        "    all_cap_letters = ['A', 'T', 'G', 'C']  # depends on dataset\n",
        "    all_cap_letters = ['A', 'C', 'G', 'T']\n",
        "\n",
        "    for li in range(len(X)):\n",
        "        letter = X[li]\n",
        "        X_onehot[all_cap_letters.index(str(letter))][li] = 1\n",
        "        #X_onehot[li][all_cap_letters.index(str(letter))] = 1\n",
        "\n",
        "    return X_onehot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCCfERGf0rMX"
      },
      "source": [
        "# sample='GGTAAACAATAATAAAAAGCCTTTGAATCTGACTTCCCTTTTGACGAGTATAAACGTACTTCAATTAGAGCTCACTGCCTTGACATAGTTCCTCCTTCAGACTTAGTCCCTGTCACAAACCCCTGCCTGGCCTGTCACAGACCCTTTACTTTTTATCTAGTTCTTACGGTCTTTACTCATGGGGACTCTCTTAACAGCCTACACAGAGTTCCCCTACCCAGCTCTAACAGCGGTGACCCTTGCTGTGGATTCTTCGCCCCACCTGCTCCCACGAGGGCACCCAGCTTGTGAAAAACCAGCTTAACCCAGATTTCTGTTCATCCATCACTCCTGCTCGCAGCGTCACCTGAAGGAGTAATCTCAGCCTCACTCGGGCAGCTTTGGGTTTTAAAAATCAATGCTGTAAAAGTGAACATTGCAGTTTCTCTGACTCCACAGCAAGTCAACTTCAACTACACTCAAGCTAACTAGGCTATGGAGCGTTTGCCGACCTCATTTACCAGGGGAACCGAATACTCTATCTTTCAATGCTAACTTTCCTGTCCTACAGTACTTCTGGAGCACTGAAAACTCCCCTAACACTCCTCTTCCCCTACCTCTGCTCTAACCTTCTCAACCAGGGGCTGTCGGTCTGGTACTCTCAAGCTGCCTCTTCCTGCAGCCATTCGAACAGTGCCCCCTAGTGGCCAGTGTTTCAAGTGCAATTGAAGAGGCTTGCAAGACTCATGCCACTGAGTCAGCTTAATTCAACATCTCTATGTGCCCAAGACTTCTCCCAGGGATATTCATTTTTAACCAGGACTATCAGTTCTTTATCCTACAAAGGCATAAGGGTAAATGAAACCAGGAGCAGACAATAAGGATATTGAGGGTTTTTATAACCTGGGCAATGGCCTGATCAAAGACTACTCAGCTTAGTACTAGCTAAACGATACTATCAGCAGTCCAGTCACCATTTCCTATAAACATCAGAAGCAGGAAGCTGTGTGGCTCTGTCATTT'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w_hm9pjmJQV"
      },
      "source": [
        "def mutation(loader, model):\n",
        "    dic = {0: [1,2,3], 1: [0, 2, 3], 2:[0,1,3], 3:[0,1,2]}\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    res = []\n",
        "    sample = []\n",
        "    for m, (data, labels) in enumerate(loader):\n",
        "        tmp = data.tolist()\n",
        "        array = np.array(tmp[0])\n",
        "        sample = np.transpose(data[0])\n",
        "        #sample = sample[200:1001-200]\n",
        "        #for i in range(669, 690): # mutating on most enriched\n",
        "        for i in range(len(array[0])):\n",
        "          if i >= 516 and i <= 526:\n",
        "            idx = np.where(array[:,i]==1)\n",
        "            mut = []\n",
        "            for val in dic[idx[0][0]]:\n",
        "              new_letter = []\n",
        "              for j in range(4):\n",
        "                if j == val:\n",
        "                  new_letter.append(1.0)\n",
        "                else:\n",
        "                  new_letter.append(0.0)\n",
        "              v = np.array(new_letter)\n",
        "              v = v.reshape((4,1))\n",
        "              new_data = np.hstack((array[:,:i], v))\n",
        "              new_data = np.hstack((new_data, array[:,i+1:]))\n",
        "              new_data = torch.from_numpy(np.array([new_data], dtype=np.float32))\n",
        "              new_set = MyDataset(new_data,labels)\n",
        "              new_loader = torch.utils.data.DataLoader(new_set, batch_size=1)\n",
        "              for k, (d, l) in enumerate(new_loader):\n",
        "                d, l = d.to(device),l.to(device)\n",
        "                with torch.no_grad():\n",
        "                    output = model(d)\n",
        "                # make our predictions\n",
        "                predicted = output.tolist()[0][0]\n",
        "                # mut.append(abs(math.log(abs(predicted/(l.tolist()[0])))))\n",
        "                mut.append(abs(abs(predicted-l.tolist()[0])/l.tolist()[0])+1)\n",
        "            res.append(max(mut))\n",
        "          else:\n",
        "            res.append(1)\n",
        "    return res, sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmgIG5YY5oMj"
      },
      "source": [
        "''' same function as above but slower runtime '''\n",
        "# def mutation(dataset, model):\n",
        "#   dic = {'A':['C','G', 'T'], 'C':['A','G','T'], 'G':['A','C','T'], 'T':['A','C','G']}\n",
        "#   seq = reverse(dataset.data[0])\n",
        "#   val = dataset.target[0]\n",
        "#   res = []\n",
        "#   for i in range(len(seq)):\n",
        "#     choices = dic[seq[i]]\n",
        "#     tmp = []\n",
        "#     for c in choices:\n",
        "#       tmp_s = seq[:i] + c + seq[i+1:]\n",
        "#       tmp.append(onehot(tmp_s))\n",
        "#     tmp_d = torch.from_numpy(np.array(tmp, dtype=np.float32))\n",
        "#     tmp_v = torch.from_numpy(np.array([val, val, val]))\n",
        "#     tmp_set = MyDataset(tmp_d, tmp_v)\n",
        "#     loader = torch.utils.data.DataLoader(tmp_set, batch_size=1)\n",
        "#     t, p = get_list_con(model, loader)\n",
        "#     tmp_max = 0\n",
        "#     for i in range(3):\n",
        "#       tmp_max = max(tmp_max, abs(p[i]-t[i]))\n",
        "#     res.append(tmp_max)\n",
        "#   return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJhNiW1a29sU"
      },
      "source": [
        "def weight_matrix(model):\n",
        "  out, input = mutation(mut_loader, model)\n",
        "  #weighted = np.zeros([601,4])\n",
        "  weighted = np.zeros([1001, 4])\n",
        "  for i in range(len(out)):\n",
        "    weighted[i] = out[i]*input[i]\n",
        "  return weighted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_UFuocvkdZc"
      },
      "source": [
        "### Heat Map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaQTuZ7BnhJQ"
      },
      "source": [
        "def mutation_each(loader, model, letter):\n",
        "    dic = {0: [letter], 1: [letter], 2:[letter], 3:[letter]}\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    res = []\n",
        "    sample = []\n",
        "    for m, (data, labels) in enumerate(loader):\n",
        "        tmp = data.tolist()\n",
        "        array = np.array(tmp[0])\n",
        "        sample = array[:,200:len(array[0])-200]\n",
        "        for i in range(200, len(array[0])-200): # mutating on 600bp\n",
        "          idx = np.where(array[:,i]==1)\n",
        "          mut = []\n",
        "          for val in dic[idx[0][0]]:\n",
        "            new_letter = []\n",
        "            for j in range(4):\n",
        "              if j == val:\n",
        "                new_letter.append(1.0)\n",
        "              else:\n",
        "                new_letter.append(0.0)\n",
        "            v = np.array(new_letter)\n",
        "            v = v.reshape((4,1))\n",
        "            new_data = np.hstack((array[:,:i], v))\n",
        "            new_data = np.hstack((new_data, array[:,i+1:]))\n",
        "            new_data = torch.from_numpy(np.array([new_data], dtype=np.float32))\n",
        "            new_set = MyDataset(new_data,labels)\n",
        "            new_loader = torch.utils.data.DataLoader(new_set, batch_size=1)\n",
        "            for k, (d, l) in enumerate(new_loader):\n",
        "              d, l = d.to(device),l.to(device)\n",
        "              with torch.no_grad():\n",
        "                  output = model(d)\n",
        "             # make our predictions\n",
        "            predicted = 0\n",
        "            for o in output.tolist():\n",
        "              predicted = (o[0])\n",
        "              res.append((predicted/l).tolist()[0])\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li9jbjKmkfXb"
      },
      "source": [
        "def heat(loader, model):\n",
        "  matrix = []\n",
        "  for i in range(4):\n",
        "    res = mutation_each(loader, model, i)\n",
        "    matrix.append(res[250:350])\n",
        "  matrix = np.array(matrix)\n",
        "  fig = plt.figure(figsize=(40, 5))\n",
        "  ax = sns.heatmap(matrix, cmap=\"YlGnBu\",  yticklabels=['A','C','G','T'])\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T13RSYelr3n3"
      },
      "source": [
        "### Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrn1KV7Ar-Yf"
      },
      "source": [
        "def negative_binomial_layer(x):\n",
        "    n,p = torch.unbind(x, dim=1)\n",
        "    n,p = [torch.unsqueeze(t,dim=-1) for t in (n,p)]\n",
        "    n = torch.nn.functional.softplus(n)\n",
        "    p = torch.sigmoid(p)\n",
        "    x = torch.cat((n,p), axis=1)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM_Sqh4xSRyu"
      },
      "source": [
        "def negative_binomial_dist(x):\n",
        "    r, p = torch.unbind(x, dim=1)\n",
        "    r, p = [torch.unsqueeze(t,dim=-1) for t in (r,p)]\n",
        "    mean, var = r*(1-p)/p, r*(1-p)/(p*p)\n",
        "    mean, var = torch.nn.functional.softplus(mean), torch.nn.functional.softplus(var)\n",
        "    # mean, var = torch.nn.functional.softplus(r), torch.nn.functional.softplus(p)\n",
        "    y = torch.cat((mean,var), axis=1)\n",
        "\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9I-rL_YYPSL"
      },
      "source": [
        "def negative_loss(pred, target):\n",
        "   #https://github.com/wukevin/babel/blob/31955790709c5b18350cd6662f21e961ce74d52a/babel/loss_functions.py#L508\n",
        "    mean,theta = torch.unbind(pred, dim=1)\n",
        "    eps = 1e-10\n",
        "    theta = torch.clamp(theta, max=1e6)\n",
        "    t1 = (\n",
        "        torch.lgamma(theta + eps)\n",
        "        + torch.lgamma(target + 1.0)\n",
        "        - torch.lgamma(target+ theta + eps)\n",
        "    )\n",
        "    t2 = (theta + target) * torch.log1p(mean / (theta + eps)) + (\n",
        "        target * (torch.log(theta + eps) - torch.log(mean + eps))\n",
        "    )\n",
        "    retval = t1 + t2\n",
        "    return torch.mean(retval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37FGTVU6sAPW"
      },
      "source": [
        "def negative_binomial_loss(pred, target):\n",
        "    n,p = torch.unbind(pred, dim=1)\n",
        "    n,p = [torch.unsqueeze(t,dim=-1) for t in (n,p)]\n",
        "    nll = (\n",
        "        torch.lgamma(n) \n",
        "        + torch.lgamma(target + 1)\n",
        "        - torch.lgamma(n + target)\n",
        "        - n * torch.log(p)\n",
        "        - target * torch.log(1 - p)\n",
        "    )    \n",
        "    return torch.mean(nll).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEUr2NVc7GDr"
      },
      "source": [
        "def logcosh(true, pred):\n",
        "    loss = torch.log(torch.cosh(pred - true))\n",
        "    return torch.sum(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "In_sPNCft4fj"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIRC3Vy-iUsm"
      },
      "source": [
        "## Training and Validating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFW99-cGiVAk"
      },
      "source": [
        "save_model_time = '0'\n",
        "mkpath = 'model/model%s'% save_model_time\n",
        "# os.makedirs(mkpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDWXRSHbiXEJ"
      },
      "source": [
        "class TrainHelper():\n",
        "    '''\n",
        "    Helper class that makes it a bit easier and cleaner to define the training routine\n",
        "    \n",
        "    '''\n",
        "\n",
        "    def __init__(self,model,train_set,test_set,opts):\n",
        "      self.model = model  # neural net\n",
        "\n",
        "      # device agnostic code snippet\n",
        "      self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "      self.model.to(self.device)\n",
        "\n",
        "      self.epochs = opts['epochs']\n",
        "\n",
        "      if opts['opt'] == 'Adam':\n",
        "        self.optimizer = torch.optim.Adam(model.parameters(), opts['lr']) # optimizer method for gradient descent\n",
        "      elif opts['opt'] == 'sgd':\n",
        "        self.optimizer = torch.optim.SGD(model.parameters(), opts['lr'])\n",
        "      elif opts['opt'] == 'adadelta':\n",
        "        self.optimizer = torch.optim.Adadelta(model.parameters(), opts['lr'])\n",
        "\n",
        "      if opts['loss_fxn'] == 'mse':\n",
        "        self.criterion = torch.nn.MSELoss()                      # loss function\n",
        "      elif opts['loss_fxn'] == 'mae':\n",
        "        self.criterion = torch.nn.L1Loss()\n",
        "      elif opts['loss_fxn'] == 'smooth':\n",
        "        self.criterion = torch.nn.SmoothL1Loss(reduction='mean')\n",
        "      elif opts['loss_fxn'] == 'huber':\n",
        "        self.criterion = torch.nn.SmoothL1Loss(reduction='mean', beta=0.3)\n",
        "      elif opts['loss_fxn'] == 'neg':\n",
        "        #self.criterion = negative_binomial_loss\n",
        "        self.criterion = negative_loss\n",
        "      elif opts['loss_fxn'] == 'cosh':\n",
        "        self.criterion = logcosh\n",
        "      elif opts['loss_fxn'] == 'poisson':\n",
        "        self.criterion = torch.nn.PoissonNLLLoss(log_input=False)\n",
        "\n",
        "      self.train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                                      batch_size=opts['batch_size'],\n",
        "                                                      shuffle=True)\n",
        "      self.valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
        "                                                      batch_size=opts['batch_size'],\n",
        "                                                      shuffle=True)\n",
        "    def train(self):\n",
        "      self.model.train() # put model in training mode\n",
        "      for epoch in range(self.epochs):\n",
        "          self.tr_loss = []\n",
        "          for i, (data,labels) in tqdm_notebook(enumerate(self.train_loader),\n",
        "                                                  total = len(self.train_loader)):\n",
        "\n",
        "              data, labels = data.to(self.device),labels.to(self.device)\n",
        "              self.optimizer.zero_grad()  \n",
        "              outputs = self.model(data)\n",
        "              loss = 0\n",
        "              if opts['loss_fxn'] != 'cosh' or opts['loss_fxn'] != 'neg' or opts['loss_fxn'] != 'poisson':\n",
        "                labels = labels.unsqueeze(1)\n",
        "                loss = self.criterion(outputs.float(), labels.float())\n",
        "              else:\n",
        "                loss = self.criterion(outputs, labels.unsqueeze(dim=-1))\n",
        "\n",
        "              loss.backward()\n",
        "              self.optimizer.step()       \n",
        "              self.tr_loss.append(loss.item())       \n",
        "          if (epoch+1) % 5 == 0 or epoch == 0: # save the model every _ epoch\n",
        "              torch.save(self.model, 'model/model{save_model_time}/net_{epoch}.pkl'.format(save_model_time=save_model_time,epoch=int((epoch+1)/5)))\n",
        "              torch.save(self.model.state_dict(), 'model/model{save_model_time}/net_params_{epoch}.pkl'.format(save_model_time=save_model_time,epoch=int((epoch+1)/5)))\n",
        "          \n",
        "          self.test(epoch) # run through the validation set\n",
        "          # print('epoch: {}, train loss: {}'.format(epoch+1, np.mean(self.tr_loss)))\n",
        "          # train_loss.append(np.mean(self.tr_loss))\n",
        "\n",
        "    def test(self,epoch):\n",
        "            \n",
        "      #self.model.eval()    # puts model in eval mode\n",
        "      self.test_loss = []\n",
        "      self.test_accuracy = []\n",
        "\n",
        "      for i, (data, labels) in enumerate(self.valid_loader):\n",
        "          \n",
        "          data, labels = data.to(self.device),labels.to(self.device)\n",
        "          # pass data through network\n",
        "          # turn off gradient calculation to speed up calcs and reduce memory\n",
        "          with torch.no_grad():\n",
        "              outputs = self.model(data)\n",
        "          # make our predictions and update our loss info\n",
        "          # labels = labels.unsqueeze(1)\n",
        "          # loss = self.criterion(outputs, labels)\n",
        "          # loss = self.criterion(outputs, labels.unsqueeze(dim=-1))\n",
        "          loss = 0\n",
        "          if opts['loss_fxn'] == 'mse':\n",
        "            labels = labels.unsqueeze(1)\n",
        "            loss = self.criterion(outputs.float(), labels.float())\n",
        "          else:\n",
        "            loss = self.criterion(outputs, labels.unsqueeze(dim=-1))\n",
        "          self.test_loss.append(loss.item())\n",
        "      \n",
        "      test_loss.append(np.mean(self.test_loss))\n",
        "      train_loss.append(np.mean(self.tr_loss))    \n",
        "      bestmodel(self.model,save_model_time,np.mean(self.test_loss)) # find best model\n",
        "      print('epoch: {}, train loss: {}, test loss: {}'.format( \n",
        "      epoch+1, np.mean(self.tr_loss), np.mean(self.test_loss)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p695YAqric1T"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRiQ3g1fieC3"
      },
      "source": [
        "train_X, train_y = shuffle(train_X, train_y, random_state=0) \n",
        "train_X_sub = train_X[:2000]\n",
        "train_y_sub = train_y[:2000]\n",
        "sub_dataset = MyDataset(train_X_sub, train_y_sub)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=True)\n",
        "sub_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL_Xxe3cihqx"
      },
      "source": [
        "def get_list_con(model, loader):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    pred, true = [], []\n",
        "    for i, (data, labels) in enumerate(loader):\n",
        "      data, labels = data.to(device),labels.to(device)\n",
        "    # pass data through network\n",
        "    # turn off gradient calculation to speed up calcs and reduce memory\n",
        "      with torch.no_grad():\n",
        "          outputs = model(data)\n",
        "    # make our predictions and update our loss info\n",
        "      predicted = []\n",
        "      for o in outputs.tolist():\n",
        "        predicted.append(o[0])\n",
        "      pred.extend(predicted)\n",
        "      true.extend(labels.tolist())\n",
        "    return true, pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WIAY5EmisD_"
      },
      "source": [
        "### AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIISQ19Kiowg"
      },
      "source": [
        "def getAUC(model):\n",
        "    labels_tr, predicts_tr = get_list_cat(model, sub_loader)\n",
        "    score_tr = metrics.roc_auc_score(labels_tr, predicts_tr, average='weighted')\n",
        "    labels_ts, predicts_ts = get_list_cat(model, test_loader)\n",
        "    score_ts = metrics.roc_auc_score(labels_ts, predicts_ts, average='weighted')\n",
        "    return score_tr, score_ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqWn5iDCPZRT"
      },
      "source": [
        "### AUPRC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ox757OrPbKl"
      },
      "source": [
        "def getAUPRC(model):\n",
        "    labels, predicts = get_list_con(model)\n",
        "    auprc = average_precision_score(labels, predicts)\n",
        "    return auprc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StwLshCMixwu"
      },
      "source": [
        "### Pearson R"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P5skco4iqVp"
      },
      "source": [
        "def getR(model):\n",
        "    labels_tr, predicts_tr = get_list_con(model, sub_loader)\n",
        "    corr_tr, _ = stats.pearsonr(labels_tr, predicts_tr)\n",
        "    labels_ts, predicts_ts = get_list_con(model, test_loader)\n",
        "    corr_ts, _ = stats.pearsonr(labels_ts, predicts_ts)\n",
        "    return corr_tr, corr_ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vQ6PjdiGc43"
      },
      "source": [
        "### Spearman R"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noyETpm9Gjmc"
      },
      "source": [
        "def getSR(model):\n",
        "    labels_tr, predicts_tr = get_list_con(model, sub_loader)\n",
        "    corr_tr, _ = stats.spearmanr(labels_tr, predicts_tr)\n",
        "    labels_ts, predicts_ts = get_list_con(model, test_loader)\n",
        "    corr_ts, _ = stats.spearmanr(labels_ts, predicts_ts)\n",
        "    return corr_tr, corr_ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqnMchGYhl7z"
      },
      "source": [
        "### R2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CBfoKrlhpDS"
      },
      "source": [
        "def getR2(model):\n",
        "  labels_tr, predicts_tr = get_list_con(model, sub_loader)\n",
        "  r2_tr = metrics.r2_score(labels_tr, predicts_tr)\n",
        "  labels_ts, predicts_ts = get_list_con(model, test_loader)\n",
        "  r2_ts = metrics.r2_score(labels_ts, predicts_ts)\n",
        "  return r2_tr, r2_ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7azqoijgT2wZ"
      },
      "source": [
        "### Average Percentage Change"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QZoksiDT71x"
      },
      "source": [
        "def avgDiff(model):\n",
        "    labels, predicts = get_list_con(model, test_loader)\n",
        "    all = []\n",
        "    for i, y in enumerate(labels):\n",
        "      div = y\n",
        "      if y == 0:\n",
        "        div = 0.0000000001\n",
        "      all.append((predicts[i]-y)/div)\n",
        "    all = np.array(all)\n",
        "    all_abs = np.absolute(all)\n",
        "    return np.mean(all_abs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-JPjltdiziI"
      },
      "source": [
        "### Plot Train Verse Test Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXqeSWbQi1wQ"
      },
      "source": [
        "def pltloss(train_loss, test_loss, epoch):\n",
        "    epochs = [i for i in range(epoch)]\n",
        "    fig = plt.figure()\n",
        "    plt.plot(epochs, train_loss, 'g', label='Training loss')\n",
        "    plt.plot(epochs, test_loss, 'b', label='Testing loss')\n",
        "    plt.title('Training and Testing Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWLOcVopi3n7"
      },
      "source": [
        "### Plot R"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XChf5ZJWi5Ie"
      },
      "source": [
        "def pltR(r_tr, r_ts, epoch):\n",
        "    epochs = [i for i in range(epoch+1)][::5][1:]\n",
        "    fig = plt.figure()\n",
        "    plt.plot(epochs, r_tr, 'g', label='Pearson R for Training')\n",
        "    plt.plot(epochs, r_ts, 'b', label='Pearson R for Testing')\n",
        "    plt.title('R Score Over Time')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('R')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcDE2mLrK6lP"
      },
      "source": [
        "def pltSR(r_tr, r_ts, epoch):\n",
        "    epochs = [i for i in range(epoch+1)][::5][1:]\n",
        "    fig = plt.figure()\n",
        "    plt.plot(epochs, r_tr, 'g', label='Spearman R for Training')\n",
        "    plt.plot(epochs, r_ts, 'b', label='Spearman R for Testing')\n",
        "    plt.title('R Score Over Time')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('R')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzBd59b8tlhT"
      },
      "source": [
        "def pltR2(r_tr, r_ts, epoch):\n",
        "    epochs = [i for i in range(epoch+1)][::5][1:]\n",
        "    fig = plt.figure()\n",
        "    plt.plot(epochs, r_tr, 'g', label='R2 for Training')\n",
        "    plt.plot(epochs, r_ts, 'b', label='R2 for Testing')\n",
        "    plt.title('R Score Over Time')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('R')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhGNPuIVi683"
      },
      "source": [
        "### Plot Predicted Verse Label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpw1m71_i8uT"
      },
      "source": [
        "def plotcomp(model, loader):\n",
        "    labels, predicts = get_list_con(model, loader)\n",
        "    fig = plt.figure()\n",
        "    plt.scatter(labels, predicts)\n",
        "    l = max(max(predicts), max(labels))\n",
        "    s = min(min(predicts), min(labels))\n",
        "    plt.plot([s, l], [s, l], color = 'black', linewidth = 1)\n",
        "    plt.title('Actual Values vs Predicted Values')\n",
        "    plt.ylabel('Predicted Values')\n",
        "    plt.xlabel('Actual Values')\n",
        "    plt.xlim(s, l)\n",
        "    plt.ylim(s, l)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iCWZtFvjKEK"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJsWCZ4fJqGk"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0QpUbW1qn7C"
      },
      "source": [
        "# class CNN(nn.Module):\n",
        "#     def __init__(self, input_size):\n",
        "#         \"\"\"\n",
        "#         init convolution and activation layers\n",
        "#         Args:\n",
        "#         x: (Nx1x2004)\n",
        "#         class: \n",
        "\n",
        "#         \"\"\"\n",
        "#         super(CNN, self).__init__() \n",
        "        \n",
        "#         self.conv1 = torch.nn.Conv1d(4, 32, 7)\n",
        "#         # self.relu = torch.nn.ReLU()\n",
        "#         # self.tanh = torch.nn.Tanh()\n",
        "#         self.gelu = torch.nn.GELU()\n",
        "#         # self.soft = torch.nn.Softplus()\n",
        "#         self.conv2 = torch.nn.Conv1d(32, 64, 7)\n",
        "#         self.conv3 = torch.nn.Conv1d(64, 64, 7)\n",
        "#         self.pool = torch.nn.MaxPool1d(7)\n",
        "#         # self.fc1 = torch.nn.Linear(64*200, 64*200)\n",
        "#         # self.fc2 = torch.nn.Linear(64*200, 1)\n",
        "#         # self.fc1 = torch.nn.Linear(64*20, 1)\n",
        "#         self.fc1 = torch.nn.Linear(12608,1)\n",
        "#         #self.gru = nn.GRU(input_size=32, hidden_size=10, num_layers=2, batch_first=True, dropout=0, bidirectional=True)\n",
        "#         #self.gru = nn.GRU(input_size=47, hidden_size=10, num_layers=2, batch_first=True, dropout=0, bidirectional=True)\n",
        "#         #self.gru = nn.GRU(input_size=58, hidden_size=10, num_layers=2, batch_first=True, dropout=0, bidirectional=True)\n",
        "#         self.gru = nn.GRU(input_size=197, hidden_size=10, num_layers=2, batch_first=True, dropout=0, bidirectional=True)\n",
        "#         # self.batch = nn.BatchNorm1d(32)\n",
        "#         # self.batch1 = nn.BatchNorm1d(64)\n",
        "#         self.dropout = nn.Dropout(p=0.2, inplace=True)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         \"\"\"\n",
        "#         forward function describes how input tensor is transformed to output tensor\n",
        "#         Args:\n",
        "            \n",
        "#         \"\"\"\n",
        "#         x = self.conv1(x)\n",
        "#         x = self.gelu(x)\n",
        "#         x = self.pool(x)\n",
        "#         x = self.dropout(x)\n",
        "#         x = self.conv2(x)\n",
        "#         x = self.gelu(x)\n",
        "#         x = self.pool(x)\n",
        "#         x = self.dropout(x)\n",
        "#         x = self.conv3(x)\n",
        "#         x = self.gelu(x)\n",
        "#         #x = self.gru(x)[0]\n",
        "#         x = torch.flatten(x, 1)\n",
        "#         x = self.fc1(x)\n",
        "#         # x = self.fc2(x)\n",
        "#         return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD253ODdjLgX"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        \"\"\"\n",
        "        init convolution and activation layers\n",
        "        Args:\n",
        "        x: \n",
        "        class: \n",
        "\n",
        "        \"\"\"\n",
        "        super(CNN, self).__init__() \n",
        "        \n",
        "        self.conv1 = torch.nn.Conv1d(input_size[0], 32, 4)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.gelu = torch.nn.GELU()\n",
        "        self.conv2 = torch.nn.Conv1d(32, 64, 4)\n",
        "        self.conv3 = torch.nn.Conv1d(64, 64, 4)\n",
        "        self.pool = torch.nn.MaxPool1d(4)\n",
        "        self.fc1 = torch.nn.Linear(64*20, 1)\n",
        "        self.fc2 = torch.nn.Linear(200*64, 1)\n",
        "        if input_size[1] == 601:\n",
        "          self.gru = nn.GRU(input_size=34, hidden_size=10, num_layers=2, batch_first=True, dropout=0, bidirectional=True)\n",
        "        elif input_size[1] == 1001:\n",
        "          self.gru = nn.GRU(input_size=58, hidden_size=10, num_layers=2, batch_first=True, dropout=0, bidirectional=True)\n",
        "        elif input_size[1] == 2001:\n",
        "          self.gru = nn.GRU(input_size=121, hidden_size=10, num_layers=2, batch_first=True, dropout=0, bidirectional=True)\n",
        "        #self.gru = nn.GRU(input_size=621, hidden_size=100, num_layers=2, batch_first=True, dropout=0, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(p=0.5, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward function describes how input tensor is transformed to output tensor\n",
        "        Args:\n",
        "            \n",
        "        \"\"\"\n",
        "        x = self.conv1(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.gru(x)[0]\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        #x = self.fc2(x)\n",
        "        #x = negative_binomial_dist(x) # convert to params of distribution (n and p)\n",
        "        #x = negative_binomial_layer(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeUxXYTXEiD0"
      },
      "source": [
        "# class CNN(nn.Module):\n",
        "#     def __init__(self, input_size):\n",
        "#         \"\"\"\n",
        "#         init convolution and activation layers\n",
        "#         Args:\n",
        "#         x: (Nx1x2004)\n",
        "#         class: \n",
        "\n",
        "#         \"\"\"\n",
        "#         super(CNN, self).__init__() \n",
        "        \n",
        "#         self.gru = nn.GRU(input_size=input_size[1], hidden_size=200, num_layers=3, batch_first=True, dropout=0.8, bidirectional=True)\n",
        "#         self.fc1 = nn.Linear(1600,1)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         \"\"\"\n",
        "#         forward function describes how input tensor is transformed to output tensor\n",
        "#         Args:\n",
        "            \n",
        "#         \"\"\"\n",
        "#         x = self.gru(x)[0]\n",
        "#         x = torch.flatten(x, 1)\n",
        "#         x = self.fc1(x)\n",
        "#         return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1UrEL0ljN3a"
      },
      "source": [
        "cnn = CNN(train_X.shape[1:])\n",
        "cnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBW2RaxFjQkq"
      },
      "source": [
        "opts = {\n",
        "    'lr': 1e-4,\n",
        "    'epochs': 25,\n",
        "    'batch_size': 100,\n",
        "    'loss_fxn': 'mse',\n",
        "    'opt': 'Adam'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP9qxmghjQ7z"
      },
      "source": [
        "test_loss, train_loss = [], []\n",
        "CNNTrainer = TrainHelper(model = cnn,\n",
        "                      train_set = train_dataset,\n",
        "                      test_set = valid_dataset, opts = opts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWBx50aNjSLA"
      },
      "source": [
        "CNNTrainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2aIZkCijXDr"
      },
      "source": [
        "#### Check for Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxZGR4JhjY3W"
      },
      "source": [
        "r_list_ts = []\n",
        "r_list_tr = []\n",
        "for num in range(opts['epochs']//5):\n",
        "  cnn.load_state_dict(torch.load('model/model'+save_model_time+'/net_params_'+str(num)+'.pkl'))\n",
        "  cnn.cuda()\n",
        "  tr, ts = getR(cnn)\n",
        "  r_list_ts.append(ts)\n",
        "  r_list_tr.append(tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTEmowccJVSX"
      },
      "source": [
        "r_list_ps = []\n",
        "r_list_pr = []\n",
        "for num in range(opts['epochs']//5):\n",
        "  cnn.load_state_dict(torch.load('model/model'+save_model_time+'/net_params_'+str(num)+'.pkl'))\n",
        "  cnn.cuda()\n",
        "  tr, ts = getSR(cnn)\n",
        "  r_list_ps.append(ts)\n",
        "  r_list_pr.append(tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osZz2Z__wFbQ"
      },
      "source": [
        "r_list_rs = []\n",
        "r_list_rr = []\n",
        "for num in range(opts['epochs']//5):\n",
        "  cnn.load_state_dict(torch.load('model/model'+save_model_time+'/net_params_'+str(num)+'.pkl'))\n",
        "  cnn.cuda()\n",
        "  tr, ts = getR2(cnn)\n",
        "  r_list_rs.append(ts)\n",
        "  r_list_rr.append(tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-pFggIspWkI"
      },
      "source": [
        "#### Mutation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFG1szuFpa5l"
      },
      "source": [
        "''' get individual value'''\n",
        "seed_everything()\n",
        "cnn.load_state_dict(torch.load('model/model'+save_model_time+'/net_params_12.pkl'))\n",
        "dummy, pred = get_list_con(cnn, mut_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHTIXOWdpkkg"
      },
      "source": [
        "mut_X = torch.from_numpy(np.array([onehot(sample)]))\n",
        "mut_Y = torch.from_numpy(np.array([pred]))\n",
        "mut_dataset = MyDataset(mut_X, mut_Y)\n",
        "mut_loader = torch.utils.data.DataLoader(mut_dataset, batch_size=1, shuffle=False)\n",
        "# reverse(mut_dataset.data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu-eeEaq6UHF"
      },
      "source": [
        "cnn.load_state_dict(torch.load('model/model'+save_model_time+'/net_params_12.pkl'))\n",
        "cnn.cuda()\n",
        "seed_everything()\n",
        "w1 = weight_matrix(cnn)\n",
        "# np.save('weight_sst_new', w1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqjG_7gNogoz"
      },
      "source": [
        "# seed_everything()\n",
        "# heat(mut_loader, cnn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT0rmLFcpt9L"
      },
      "source": [
        "#### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT5d0wkFjZbK"
      },
      "source": [
        "pltloss(train_loss, test_loss, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7BcOx7vjcA9"
      },
      "source": [
        "pltR(r_list_tr, r_list_ts, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anPYl8V5Kv2e"
      },
      "source": [
        "pltSR(r_list_pr, r_list_ps, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9iljc8FURv6"
      },
      "source": [
        "pltR2(r_list_rr, r_list_rs, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYPZvLRCjeaF"
      },
      "source": [
        "seed_everything()\n",
        "plotcomp(cnn, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLv48G-_Zh0m"
      },
      "source": [
        "seed_everything()\n",
        "plotcomp(cnn, sub_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1p3p_6ey38c"
      },
      "source": [
        "''' extract cnn layer '''\n",
        "# layer_shape = cnn.conv1.weight.shape\n",
        "# for i in range(layer_shape[0]):\n",
        "#     fig = plt.figure(figsize = (5, 5))\n",
        "#     plt.imshow(cnn.conv1.weight[i].detach().numpy(), cmap = 'Blues')\n",
        "#     fig.subplots_adjust(right=0.85)\n",
        "#     cax = plt.axes([0.9, 0.1, 0.075, 0.8])\n",
        "#     plt.colorbar(cax=cax)\n",
        "#     plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nweE-Te-AZoV"
      },
      "source": [
        "### Basenji"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgD0BKRlD5cE"
      },
      "source": [
        "''' original version based on https://github.com/calico/basenji/blob/master/manuscripts/genome_research2018/params.txt '''\n",
        "class Besenji(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        \"\"\"\n",
        "        init convolution and activation layers\n",
        "        Args:\n",
        "        class: \n",
        "\n",
        "        \"\"\"\n",
        "        super(Besenji, self).__init__() \n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.05)\n",
        "        self.dropout1 = nn.Dropout(p=0.1)\n",
        "        self.batch6 = nn.BatchNorm1d(108)\n",
        "\n",
        "        self.conv1 = nn.Conv1d(input_size[0], 312, kernel_size=22)\n",
        "        self.batch1 = nn.BatchNorm1d(312)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(312, 368, kernel_size=1)\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        self.batch2 = nn.BatchNorm1d(368)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(368, 435, kernel_size=6)\n",
        "        self.pool3 = nn.MaxPool1d(4)\n",
        "        self.batch3 = nn.BatchNorm1d(435)\n",
        "\n",
        "        self.conv4 = nn.Conv1d(435, 607, kernel_size=6)\n",
        "        self.pool4 = nn.MaxPool1d(4)\n",
        "        self.batch4 = nn.BatchNorm1d(607)\n",
        "        \n",
        "        self.conv5 = nn.Conv1d(607, 717, kernel_size=3)\n",
        "        self.batch5 = nn.BatchNorm1d(717)\n",
        "\n",
        "        self.conv6 = nn.Conv1d(717, 108, kernel_size=3, dilation=2)\n",
        "\n",
        "        self.conv7 = nn.Conv1d(108, 108, kernel_size=3, dilation=4)\n",
        "\n",
        "        self.conv8 = nn.Conv1d(108, 108, kernel_size=3, dilation=8)\n",
        "\n",
        "        self.conv9 = nn.Conv1d(108, 108, kernel_size=3, dilation=16)\n",
        "        \n",
        "        self.conv10 = nn.Conv1d(108, 108, kernel_size=3, dilation=32)\n",
        "\n",
        "        self.conv11 = nn.Conv1d(108, 108, kernel_size=3, dilation=64)\n",
        "\n",
        "        self.conv12 = nn.Conv1d(108, 1365, kernel_size=1)\n",
        "        self.batch12 = nn.BatchNorm1d(1365)\n",
        "\n",
        "        self.conv13 = nn.Conv1d(1365, 1, kernel_size=1)\n",
        "        self.fc1 = torch.nn.Linear(15, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch1(self.conv1(x))\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.batch2(self.conv2(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.batch3(self.conv3(x)))\n",
        "        x = self.pool3(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.batch4(self.conv4(x)))\n",
        "        x = self.pool4(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.batch5(self.conv5(x)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.batch6(self.conv6(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.relu(self.batch6(self.conv7(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.relu(self.batch6(self.conv8(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.relu(self.batch6(self.conv9(x)))\n",
        "        x = self.dropout1(x)\n",
        "        \n",
        "        x = self.relu(self.batch6(self.conv10(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.relu(self.batch6(self.conv11(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.relu(self.batch12(self.conv12(x)))\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.conv13(x)\n",
        "        \n",
        "        x = torch.flatten(x, 1)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R0AEXiDAbL8"
      },
      "source": [
        "''' modified version '''\n",
        "class Besenji(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        \"\"\"\n",
        "        init convolution and activation layers\n",
        "        Args:\n",
        "        class: \n",
        "\n",
        "        \"\"\"\n",
        "        super(Besenji, self).__init__() \n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.05)\n",
        "        self.dropout1 = nn.Dropout(p=0.1)\n",
        "        self.batch6 = nn.BatchNorm1d(108)\n",
        "\n",
        "        self.conv1 = nn.Conv1d(4, 312, kernel_size=2)\n",
        "        self.batch1 = nn.BatchNorm1d(312)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(312, 368, kernel_size=1)\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        self.batch2 = nn.BatchNorm1d(368)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(368, 435, kernel_size=2)\n",
        "        self.pool3 = nn.MaxPool1d(2)\n",
        "        self.batch3 = nn.BatchNorm1d(435)\n",
        "\n",
        "        self.conv4 = nn.Conv1d(435, 607, kernel_size=2)\n",
        "        self.pool4 = nn.MaxPool1d(2)\n",
        "        self.batch4 = nn.BatchNorm1d(607)\n",
        "        \n",
        "        self.conv5 = nn.Conv1d(607, 717, kernel_size=3)\n",
        "        self.batch5 = nn.BatchNorm1d(717)\n",
        "\n",
        "        self.conv6 = nn.Conv1d(717, 108, kernel_size=3, dilation=2)\n",
        "\n",
        "        self.conv7 = nn.Conv1d(108, 108, kernel_size=3, dilation=4)\n",
        "\n",
        "        self.conv8 = nn.Conv1d(108, 108, kernel_size=3, dilation=8)\n",
        "\n",
        "        self.conv9 = nn.Conv1d(108, 108, kernel_size=3, dilation=16)\n",
        "        \n",
        "        self.conv10 = nn.Conv1d(108, 108, kernel_size=3, dilation=32)\n",
        "\n",
        "        self.conv11 = nn.Conv1d(108, 108, kernel_size=3, dilation=64)\n",
        "\n",
        "        self.conv12 = nn.Conv1d(108, 1365, kernel_size=1)\n",
        "        self.batch12 = nn.BatchNorm1d(1365)\n",
        "\n",
        "        self.conv13 = nn.Conv1d(1365, 1, kernel_size=1)\n",
        "        self.fc1 = torch.nn.Linear(12, 1)\n",
        "        #self.fc2 = torch.nn.Linear(68, 1)\n",
        "        #self.fc2 = torch.nn.Linear(93, 1)\n",
        "        #self.fc2 = torch.nn.Linear(118, 1)\n",
        "        self.fc2 = torch.nn.Linear(243, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch1(self.conv1(x))\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.batch2(self.conv2(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.batch3(self.conv3(x)))\n",
        "        x = self.pool3(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.batch4(self.conv4(x)))\n",
        "        x = self.pool4(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.relu(self.batch5(self.conv5(x)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.batch6(self.conv6(x)))\n",
        "        x = self.dropout1(x)\n",
        "        # print(x.size())\n",
        "\n",
        "        # x = self.relu(self.batch6(self.conv7(x)))\n",
        "        # x = self.dropout1(x)\n",
        "        # # print(x.size())\n",
        "\n",
        "        # x = self.relu(self.batch6(self.conv8(x)))\n",
        "        # x = self.dropout1(x)\n",
        "        # # print(x.size())\n",
        "\n",
        "        # x = self.relu(self.batch6(self.conv9(x)))\n",
        "        # x = self.dropout1(x)\n",
        "        # print(x.size())\n",
        "        \n",
        "        # x = self.relu(self.batch6(self.conv10(x)))\n",
        "        # x = self.dropout1(x)\n",
        "        # print(x.size())\n",
        "\n",
        "        # x = self.relu(self.batch6(self.conv11(x)))\n",
        "        # x = self.dropout1(x)\n",
        "        # print(x.size())\n",
        "\n",
        "        x = self.relu(self.batch12(self.conv12(x)))\n",
        "        x = self.dropout(x)\n",
        "        # print(x.size())\n",
        "      \n",
        "        x = self.conv13(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        # x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        # print(x.size())\n",
        "        # assert 0\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huRCjHnNyiwp"
      },
      "source": [
        "basenji = Besenji(train_X.shape[1:])\n",
        "basenji"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW1OpyB9y8Oe"
      },
      "source": [
        "opts = {\n",
        "    'lr': 1e-4,\n",
        "    'epochs': 50,\n",
        "    'batch_size': 100,\n",
        "    'loss_fxn': 'smooth',\n",
        "    'opt': 'sgd'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HYlU3yxy-KF"
      },
      "source": [
        "test_loss, train_loss = [], []\n",
        "BasenjiTrainer = TrainHelper(model = basenji,\n",
        "                      train_set = train_dataset,\n",
        "                      test_set = valid_dataset, opts = opts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFUbd7k_zEIo"
      },
      "source": [
        "BasenjiTrainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leqbl5WEj7DG"
      },
      "source": [
        "#### Check for Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzRPbYmIj-8R"
      },
      "source": [
        "r_list_ts = []\n",
        "r_list_tr = []\n",
        "for num in range(opts['epochs']//5):\n",
        "  basenji.load_state_dict(torch.load('model/model'+save_model_time+'/net_params_'+str(num)+'.pkl'))\n",
        "  basenji.cuda()\n",
        "  tr, ts = getR(basenji)\n",
        "  r_list_ts.append(ts)\n",
        "  r_list_tr.append(tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqU0fpatq_JS"
      },
      "source": [
        "#### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj0WR9ZrkDSA"
      },
      "source": [
        "pltloss(train_loss, test_loss, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bpo0aJ5WkGnr"
      },
      "source": [
        "pltR(r_list_tr, r_list_ts, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppMmDXx2kI7C"
      },
      "source": [
        "plotcomp(basenji,test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNsR_mYZI9z0"
      },
      "source": [
        "### VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXAF6ZvMI-24"
      },
      "source": [
        "class VGG16(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(VGG16, self).__init__()\n",
        "        self.conv1_1 = nn.Conv1d(input_size[0], 64, kernel_size=4, padding=1)\n",
        "        self.conv1_2 = nn.Conv1d(64, 64, kernel_size=4, padding=1)\n",
        "\n",
        "        self.conv2_1 = nn.Conv1d(64, 128, kernel_size=4, padding=1)\n",
        "        self.conv2_2 = nn.Conv1d(128, 128, kernel_size=4, padding=1)\n",
        "\n",
        "        self.conv3_1 = nn.Conv1d(128, 256, kernel_size=4, padding=1)\n",
        "        self.conv3_2 = nn.Conv1d(256, 256, kernel_size=4, padding=1)\n",
        "        self.conv3_3 = nn.Conv1d(256, 256, kernel_size=4, padding=1)\n",
        "\n",
        "        self.conv4_1 = nn.Conv1d(256, 512, kernel_size=4, padding=1)\n",
        "        self.conv4_2 = nn.Conv1d(512, 512, kernel_size=4, padding=1)\n",
        "        self.conv4_3 = nn.Conv1d(512, 512, kernel_size=4, padding=1)\n",
        "\n",
        "        self.conv5_1 = nn.Conv1d(512, 512, kernel_size=4, padding=1)\n",
        "        self.conv5_2 = nn.Conv1d(512, 512, kernel_size=4, padding=1)\n",
        "        self.conv5_3 = nn.Conv1d(512, 512, kernel_size=4, padding=1)\n",
        "\n",
        "        #self.gru = nn.GRU(input_size=18, hidden_size=10, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        # max pooling (kernel_size, stride)\n",
        "        self.pool = nn.MaxPool1d(4, 4)\n",
        "\n",
        "        # fully conected layers\n",
        "        #self.fc6 = nn.Linear(512*18, 1000)\n",
        "        #self.fc6 = nn.Linear(512*20, 1000)\n",
        "        self.fc6 = nn.Linear(512*9, 1000)\n",
        "        self.fc7 = nn.Linear(1000, 1000)\n",
        "        self.fc8 = nn.Linear(1000, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv1_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.conv2_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.conv3_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3_3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.conv4_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv4_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv4_3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.relu(self.conv5_1(x))\n",
        "        x = self.relu(self.conv5_2(x))\n",
        "        x = self.relu(self.conv5_3(x))\n",
        "        x = self.pool(x)\n",
        "        # print(x.size())\n",
        "        #x = self.gru(x)[0]\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc6(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc7(x)\n",
        "        # x = self.log(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1IrfLc5JB9V"
      },
      "source": [
        "vgg = VGG16(train_X.shape[1:])\n",
        "vgg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXpvPZfxJZEv"
      },
      "source": [
        "opts = {\n",
        "    'lr': 1e-3,\n",
        "    'epochs': 25,\n",
        "    'batch_size': 100,\n",
        "    'loss_fxn': 'mse',\n",
        "    'opt': 'sgd'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz11EKpYJbyj"
      },
      "source": [
        "test_loss, train_loss = [], []\n",
        "VGGTrainer = TrainHelper(model = vgg,\n",
        "                      train_set = train_dataset,\n",
        "                      test_set = valid_dataset, opts = opts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bePHehgIJheF"
      },
      "source": [
        "VGGTrainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZBEnge2JuYD"
      },
      "source": [
        "#### Check for Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9cnPwATJvwO"
      },
      "source": [
        "r_list_ts = []\n",
        "r_list_tr = []\n",
        "for num in range(opts['epochs']//5):\n",
        "  vgg.load_state_dict(torch.load('model/model'+save_model_time+'/net_params_'+str(num)+'.pkl'))\n",
        "  vgg.cuda()\n",
        "  tr, ts = getR(vgg)\n",
        "  r_list_ts.append(ts)\n",
        "  r_list_tr.append(tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOyLTKA9rFpm"
      },
      "source": [
        "#### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__RVV7rkJ1SO"
      },
      "source": [
        "pltloss(train_loss, test_loss, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYI2AZxVJ4Mh"
      },
      "source": [
        "pltR(r_list_tr, r_list_ts, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2JQEsp-PybT"
      },
      "source": [
        "plotcomp(vgg,test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRWK6G4EjC42"
      },
      "source": [
        "### Char Plant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKpNj8OajFht"
      },
      "source": [
        "class CHAR(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        \"\"\"\n",
        "        init convolution and activation layers\n",
        "        Args:\n",
        "        class: \n",
        "\n",
        "        \"\"\"\n",
        "        super(CHAR, self).__init__() \n",
        "        \n",
        "        self.conv1 = torch.nn.Conv1d(input_size[0], 200, 19, padding=\"same\")\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.conv2 = torch.nn.Conv1d(200, 100, 11, padding=\"same\")\n",
        "        self.fc1 = torch.nn.Linear(62500, 200)\n",
        "        self.fc2 = torch.nn.Linear(200, 1)\n",
        "        self.dropout = nn.Dropout(p=0.6)\n",
        "        self.gru = nn.GRU(input_size=62, hidden_size=31, num_layers=2, batch_first=True, dropout=0.6, bidirectional=True)\n",
        "        self.pool = nn.MaxPool1d(4, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward function describes how input tensor is transformed to output tensor\n",
        "        Args:\n",
        "            \n",
        "        \"\"\"\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.pool(x)\n",
        "        #print(x.size())\n",
        "        #x = self.gru(x)[0]\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t0LIm5YlV2P"
      },
      "source": [
        "char = CHAR(train_X.shape[1:])\n",
        "char"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8KvuXZaYP86"
      },
      "source": [
        "opts = {\n",
        "    'lr': 1e-4,\n",
        "    'epochs': 50,\n",
        "    'batch_size': 100,\n",
        "    'loss_fxn': 'mse',\n",
        "    'opt': 'Adam'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cY3ijo9YVaZ"
      },
      "source": [
        "test_loss, train_loss = [], []\n",
        "CharTrainer = TrainHelper(model = char,\n",
        "                      train_set = train_dataset,\n",
        "                      test_set = valid_dataset, opts = opts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXaEY8nmYZ0u"
      },
      "source": [
        "CharTrainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOdtMBjwceZa"
      },
      "source": [
        "#### Check for Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l7bd8b0chjr"
      },
      "source": [
        "r_list_ts = []\n",
        "r_list_tr = []\n",
        "for num in range(opts['epochs']//5):\n",
        "  char.load_state_dict(torch.load('model/model'+save_model_time+'/net_params_'+str(num)+'.pkl'))\n",
        "  char.cuda()\n",
        "  tr, ts = getR(char)\n",
        "  r_list_ts.append(ts)\n",
        "  r_list_tr.append(tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe3kkegBrRrX"
      },
      "source": [
        "#### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqj3yWwTcw6q"
      },
      "source": [
        "pltR(r_list_tr, r_list_ts, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b8fWb5-cy7l"
      },
      "source": [
        "plotcomp(char,test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qcx6gjmAB5b"
      },
      "source": [
        "### AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJMw4MWuADIu"
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        \"\"\"\n",
        "        init convolution and activation layers\n",
        "        Args:\n",
        "        class: \n",
        "\n",
        "        \"\"\"\n",
        "        super(AlexNet, self).__init__() \n",
        "        \n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv1d(4, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
        "            nn.Conv1d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
        "            nn.Conv1d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv1d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv1d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool1d(6)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6, 256 * 4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 4, 256 * 4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256 * 4, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward function describes how input tensor is transformed to output tensor\n",
        "        Args:\n",
        "            \n",
        "        \"\"\"\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guGyX1Q0Ar2K"
      },
      "source": [
        "alex = AlexNet(train_X.shape[1:])\n",
        "alex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1TkzPUUAzVK"
      },
      "source": [
        "opts = {\n",
        "    'lr': 1e-4,\n",
        "    'epochs': 50,\n",
        "    'batch_size': 256,\n",
        "    'loss_fxn': 'mse',\n",
        "    'opt': 'Adam'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjU4sHUlA1MI"
      },
      "source": [
        "test_loss, train_loss = [], []\n",
        "alexTrainer = TrainHelper(model = alex,\n",
        "                      train_set = train_dataset,\n",
        "                      test_set = valid_dataset, opts = opts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qELumURwA34G"
      },
      "source": [
        "alexTrainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvMBV3cdA8Xa"
      },
      "source": [
        "#### Check for Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SatJ8DQOA-Vx"
      },
      "source": [
        "r_list_ts = []\n",
        "r_list_tr = []\n",
        "for num in range(opts['epochs']//5):\n",
        "  alex.load_state_dict(torch.load('model/model'+save_model_time+'/net_params_'+str(num)+'.pkl'))\n",
        "  alex.cuda()\n",
        "  tr, ts = getR(alex)\n",
        "  r_list_ts.append(ts)\n",
        "  r_list_tr.append(tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NwICVHlrVul"
      },
      "source": [
        "#### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a3JezuyBEmx"
      },
      "source": [
        "pltR(r_list_tr, r_list_ts, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ-mXi9MBHo5"
      },
      "source": [
        "plotcomp(alex,test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQOdERNORcKk"
      },
      "source": [
        "### LeNet5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckxAatfdReQo"
      },
      "source": [
        "class LeNet5(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size):\n",
        "        super(LeNet5, self).__init__()\n",
        "        \n",
        "        self.feature_extractor = nn.Sequential(            \n",
        "            nn.Conv1d(in_channels=input_size[0], out_channels=6, kernel_size=5, stride=1),\n",
        "            nn.GELU(),\n",
        "            nn.MaxPool1d(kernel_size=2),\n",
        "            nn.Conv1d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
        "            nn.GELU(),\n",
        "            nn.MaxPool1d(kernel_size=2),\n",
        "            nn.Conv1d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=299160, out_features=100),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(in_features=100, out_features=1),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "      \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbIcMRhP0ylx"
      },
      "source": [
        "lenet = LeNet5(train_X.shape[1:])\n",
        "lenet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ou_S16902mY"
      },
      "source": [
        "opts = {\n",
        "    'lr': 2e-5,\n",
        "    'epochs': 50,\n",
        "    'batch_size': 100,\n",
        "    'loss_fxn': 'mse',\n",
        "    'opt': 'Adam'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF9ZVWj-08GZ"
      },
      "source": [
        "test_loss, train_loss = [], []\n",
        "lenetTrainer = TrainHelper(model = lenet,\n",
        "                      train_set = train_dataset,\n",
        "                      test_set = valid_dataset, opts = opts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B67gOwTO0-lk"
      },
      "source": [
        "lenetTrainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tmhcm2fy8vcu"
      },
      "source": [
        "#### Check for Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XecrOsGD7Pb6"
      },
      "source": [
        "r_list_ts = []\n",
        "r_list_tr = []\n",
        "for num in range(opts['epochs']//5):\n",
        "  lenet.load_state_dict(torch.load('model/model'+save_model_time+'/net_params_'+str(num)+'.pkl'))\n",
        "  lenet.cuda()\n",
        "  tr, ts = getR(lenet)\n",
        "  r_list_ts.append(ts)\n",
        "  r_list_tr.append(tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l3IEzVYrav5"
      },
      "source": [
        "#### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWIVAyOV83D1"
      },
      "source": [
        "pltR(r_list_tr, r_list_ts, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI8qy1D286dO"
      },
      "source": [
        "plotcomp(lenet,sub_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72ZLfavmPUtu"
      },
      "source": [
        "### ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CkwJ7-09XOP"
      },
      "source": [
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv1d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "def conv5x5(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv1d(in_planes, out_planes, kernel_size=5, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "def conv7x7(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv1d(in_planes, out_planes, kernel_size=7, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "\n",
        "class BasicBlock3x3_1(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes3_1, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock3x3_1, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes3_1, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm1d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm1d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class BasicBlock3x3_2(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes3_2, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock3x3_2, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes3_2, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm1d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm1d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class BasicBlock3x3_3(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes3_3, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock3x3_3, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes3_3, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm1d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm1d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class MSResNet(nn.Module):\n",
        "    def __init__(self, input_channel, layers=[2, 2, 2, 2], num_classes=1):\n",
        "        self.inplanes3_1 = 64\n",
        "        self.inplanes3_2 = 64\n",
        "        self.inplanes3_3 = 64\n",
        "\n",
        "        super(MSResNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(input_channel, 64, kernel_size=5, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer3x3_11 = self._make_layer3_1(BasicBlock3x3_1, 64, layers[0], stride=2)\n",
        "        self.layer3x3_12 = self._make_layer3_1(BasicBlock3x3_1, 128, layers[1], stride=2)\n",
        "        self.layer3x3_13 = self._make_layer3_1(BasicBlock3x3_1, 256, layers[2], stride=2)\n",
        "        #self.layer3x3_14 = self._make_layer3_1(BasicBlock3x3_1, 512, layers[3], stride=2)\n",
        "\n",
        "        # maxplooing kernel size: 16, 11, 6\n",
        "        self.maxpool3_1 = nn.AdaptiveAvgPool1d(3)\n",
        "        #(kernel_size=3, stride=1, padding=0)\n",
        "\n",
        "        self.layer3x3_21 = self._make_layer3_2(BasicBlock3x3_2, 64, layers[0], stride=2)\n",
        "        self.layer3x3_22 = self._make_layer3_2(BasicBlock3x3_2, 128, layers[1], stride=2)\n",
        "        self.layer3x3_23 = self._make_layer3_2(BasicBlock3x3_2, 256, layers[2], stride=2)\n",
        "        #self.layer3x3_24 = self._make_layer3_2(BasicBlock3x3_2, 512, layers[3], stride=2)\n",
        "\n",
        "        # maxplooing kernel size: 16, 11, 6\n",
        "        self.maxpool3_2 = nn.AdaptiveAvgPool1d(3)\n",
        "        #(kernel_size=3, stride=1, padding=0)\n",
        "\n",
        "        self.layer3x3_31 = self._make_layer3_3(BasicBlock3x3_3, 64, layers[0], stride=2)\n",
        "        self.layer3x3_32 = self._make_layer3_3(BasicBlock3x3_3, 128, layers[1], stride=2)\n",
        "        self.layer3x3_33 = self._make_layer3_3(BasicBlock3x3_3, 256, layers[2], stride=2)\n",
        "        #self.layer3x3_34 = self._make_layer3_3(BasicBlock3x3_3, 512, layers[3], stride=2)\n",
        "\n",
        "        # maxplooing kernel size: 16, 11, 6\n",
        "        self.maxpool3_3 = nn.AdaptiveAvgPool1d(3)\n",
        "        #(kernel_size=3, stride=1, padding=0)\n",
        "\n",
        "        self.drop = nn.Dropout(p=0.2)\n",
        "        #self.fc = nn.Linear(256*51, num_classes)\n",
        "        self.fc = nn.Linear(256*9, num_classes)\n",
        "\n",
        "\n",
        "    def _make_layer3_1(self, block, planes, blocks, stride=2):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes3_1 != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv1d(self.inplanes3_1, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm1d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes3_1, planes, stride, downsample))\n",
        "        self.inplanes3_1 = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes3_1, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _make_layer3_2(self, block, planes, blocks, stride=2):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes3_2 != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv1d(self.inplanes3_2, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm1d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes3_2, planes, stride, downsample))\n",
        "        self.inplanes3_2 = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes3_2, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def _make_layer3_3(self, block, planes, blocks, stride=2):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes3_3 != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv1d(self.inplanes3_3, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm1d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes3_3, planes, stride, downsample))\n",
        "        self.inplanes3_3 = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes3_3, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x0):\n",
        "        x0 = self.conv1(x0)\n",
        "        x0 = self.bn1(x0)\n",
        "        x0 = self.relu(x0)\n",
        "        x0 = self.maxpool(x0)\n",
        "\n",
        "        x = self.layer3x3_11(x0)\n",
        "        x = self.layer3x3_12(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.layer3x3_13(x)\n",
        "        # x = self.layer3x3_14(x)\n",
        "        x = self.maxpool3_1(x)\n",
        "\n",
        "        y = self.layer3x3_21(x0)\n",
        "        y = self.layer3x3_22(y)\n",
        "        y = self.drop(y)\n",
        "        y = self.layer3x3_23(y)\n",
        "        # y = self.layer3x3_24(y)\n",
        "        y = self.maxpool3_2(y)\n",
        "\n",
        "        z = self.layer3x3_31(x0)\n",
        "        z = self.layer3x3_32(z)\n",
        "        z = self.drop(z)\n",
        "        z = self.layer3x3_33(z)\n",
        "        # z = self.layer3x3_34(z)\n",
        "        z = self.maxpool3_3(z)\n",
        "\n",
        "        out = torch.cat([x, y, z], dim=1)\n",
        "        out = torch.flatten(out, 1)\n",
        "\n",
        "        out = self.fc(out)\n",
        "  \n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q6L0rmo9xRz"
      },
      "source": [
        "resNet = MSResNet(4)\n",
        "resNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiaqBXPgPl4M"
      },
      "source": [
        "''' fastai ver resnet '''\n",
        "from fastai.basics import *\n",
        "from fastai.callback.all import *\n",
        "from fastai.vision.all import *\n",
        "from fastai.vision.models.xresnet import *\n",
        "from fastai.metrics import *\n",
        "from fastai.layers import *\n",
        "resNet = xresnet18(c_in=4, n_out=1, ndim=1, pretrained=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeoBO8qDQmz2"
      },
      "source": [
        "opts = {\n",
        "    'lr': 1e-4,\n",
        "    'epochs': 15,\n",
        "    'batch_size': 100,\n",
        "    'loss_fxn': 'mse',\n",
        "    'opt': 'Adam'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYKVUBLLQv3v"
      },
      "source": [
        "test_loss, train_loss = [], []\n",
        "resnetTrainer = TrainHelper(model = resNet,\n",
        "                      train_set = train_dataset,\n",
        "                      test_set = valid_dataset, opts = opts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AsfvmWBQ2yt"
      },
      "source": [
        "resnetTrainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iXv1CTCclWv"
      },
      "source": [
        "#### Check for Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5J2GfRdU5fA"
      },
      "source": [
        "r_list_ts = []\n",
        "r_list_tr = []\n",
        "for num in range(opts['epochs']//5):\n",
        "  resNet.load_state_dict(torch.load('model/model'+save_model_time+'/net_params_'+str(num)+'.pkl'))\n",
        "  resNet.cuda()\n",
        "  tr, ts = getR(resNet)\n",
        "  r_list_ts.append(ts)\n",
        "  r_list_tr.append(tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq1FZ-FkffR0"
      },
      "source": [
        "r_list_rs = []\n",
        "r_list_rr = []\n",
        "for num in range(opts['epochs']//5):\n",
        "  resNet.load_state_dict(torch.load('model/model'+save_model_time+'/net_params_'+str(num)+'.pkl'))\n",
        "  resNet.cuda()\n",
        "  tr, ts = getR2(resNet)\n",
        "  r_list_rs.append(ts)\n",
        "  r_list_rr.append(tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H3HucnUisSs"
      },
      "source": [
        "r_list_ps = []\n",
        "r_list_pr = []\n",
        "for num in range(opts['epochs']//5):\n",
        "  resNet.load_state_dict(torch.load('model/model'+save_model_time+'/net_params_'+str(num)+'.pkl'))\n",
        "  resNet.cuda()\n",
        "  tr, ts = getSR(resNet)\n",
        "  r_list_ps.append(ts)\n",
        "  r_list_pr.append(tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6obmrhKqkdB"
      },
      "source": [
        "#### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tlk7VY9YC9-_"
      },
      "source": [
        "pltloss(train_loss, test_loss, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMXaXZaTcbnb"
      },
      "source": [
        "pltR(r_list_tr, r_list_ts, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfrYjruD3kwL"
      },
      "source": [
        "pltSR(r_list_pr, r_list_ps, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f32soMsXtrt8"
      },
      "source": [
        "pltR2(r_list_rr, r_list_rs, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XpAm25Tco_I"
      },
      "source": [
        "plotcomp(resNet,test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}