{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "single_cell_continuous.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9aIRaaghtOe"
      },
      "source": [
        "## Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwoRZsWohI59"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#from pytorch_transformers import BertModel, BertTokenizer, BertConfig, WarmupLinearSchedule \n",
        "import re\n",
        "import pandas as pd \n",
        "import json\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "import pickle\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import f1_score, recall_score\n",
        "from scipy import stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVcqZRjDhr2B"
      },
      "source": [
        "from tqdm import tqdm_notebook, trange\n",
        "\n",
        "def seed_everything(seed = 42): \n",
        "  random.seed(seed) \n",
        "  os.environ['PYTHONHASHSEED'] = str(seed) \n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed) \n",
        "  torch.cuda.manual_seed(seed) \n",
        "  torch.backends.cudnn.deterministic = True\n",
        "# For reproducible results\n",
        "seed_everything()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC_LhMbUhwQz"
      },
      "source": [
        "import matplotlib as mpl\n",
        "mpl.style.use('seaborn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1K6fXLehyQG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEbbi9A1hzWh"
      },
      "source": [
        "%cd /content/gdrive/My Drive/seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGOw2CTYh45K"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPDF3xLYh0j3"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.data = X\n",
        "        self.target = Y\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByZDT2mwh6F4"
      },
      "source": [
        "npzfile = np.load('data/norm/Astrocytes_norm.npz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb7CPf8DiCEY"
      },
      "source": [
        "X, y = npzfile['arr_0'], npzfile['arr_1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2kzVWMWiDI_"
      },
      "source": [
        "subX, subY = shuffle(X, y, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e-RevIdiFM7"
      },
      "source": [
        "testX = subX[int(len(subY)*0.8):]\n",
        "testY = subY[int(len(subY)*0.8):]\n",
        "validX = subX[int(len(subY)*0.6):int(len(subY)*0.8)]\n",
        "validY = subY[int(len(subY)*0.6):int(len(subY)*0.8)]\n",
        "trainX = subX[:int(len(subY)*0.6)]\n",
        "trainY = subY[:int(len(subY)*0.6)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCCN-ybriJJ3"
      },
      "source": [
        "### Convert to Torch Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfnxuDCbiLMH"
      },
      "source": [
        "train_X = torch.from_numpy(trainX)\n",
        "train_y = torch.from_numpy(trainY)\n",
        "valid_X  = torch.from_numpy(validX)\n",
        "valid_y = torch.from_numpy(validY)\n",
        "test_X = torch.from_numpy(testX)\n",
        "test_y = torch.from_numpy(testY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB79nKP-iMPH"
      },
      "source": [
        "train_dataset = MyDataset(train_X, train_y)\n",
        "valid_dataset = MyDataset(valid_X, valid_y)\n",
        "test_dataset = MyDataset(test_X, test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZdT2YjkiPGU"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNGCp8RxiPWy"
      },
      "source": [
        "def bestmodel(model_name,save_model_time,valid_loss):\n",
        "    bestloss = 10000\n",
        "    if valid_loss < bestloss :\n",
        "        bestloss = valid_loss\n",
        "        torch.save(model_name, 'model/model{save_model_time}/bestmodel.pkl'.format(save_model_time=save_model_time))\n",
        "        torch.save(model_name.state_dict(), 'model/model{save_model_time}/net_params_bestmodel.pkl'.format(save_model_time=save_model_time))\n",
        "    return True  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIRC3Vy-iUsm"
      },
      "source": [
        "## Training and Validating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFW99-cGiVAk"
      },
      "source": [
        "save_model_time = '0'\n",
        "mkpath = 'model/model%s'% save_model_time\n",
        "# os.makedirs(mkpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDWXRSHbiXEJ"
      },
      "source": [
        "class TrainHelper():\n",
        "    '''\n",
        "    Helper class that makes it a bit easier and cleaner to define the training routine\n",
        "    \n",
        "    '''\n",
        "\n",
        "    def __init__(self,model,train_set,test_set,opts):\n",
        "      self.model = model  # neural net\n",
        "\n",
        "      # device agnostic code snippet\n",
        "      self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "      self.model.to(self.device)\n",
        "\n",
        "      self.epochs = opts['epochs']\n",
        "      self.optimizer = torch.optim.Adam(model.parameters(), opts['lr']) # optimizer method for gradient descent\n",
        "      #self.optimizer = torch.optim.SGD(model.parameters(), opts['lr'])\n",
        "      self.criterion = torch.nn.MSELoss()\n",
        "      self.train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                                      batch_size=opts['batch_size'],\n",
        "                                                      shuffle=True)\n",
        "      self.valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
        "                                                      batch_size=opts['batch_size'],\n",
        "                                                      shuffle=True)\n",
        "    def train(self):\n",
        "      self.model.train() # put model in training mode\n",
        "      for epoch in range(self.epochs):\n",
        "          self.tr_loss = []\n",
        "          for i, (data,labels) in tqdm_notebook(enumerate(self.train_loader),\n",
        "                                                  total = len(self.train_loader)):\n",
        "\n",
        "              data, labels = data.to(self.device),labels.to(self.device)\n",
        "              self.optimizer.zero_grad()  \n",
        "              outputs = self.model(data)\n",
        "              labels = labels.unsqueeze(1)\n",
        "              loss = self.criterion(outputs.float(), labels.float())\n",
        "              loss.backward()                        \n",
        "              self.optimizer.step()                  \n",
        "              self.tr_loss.append(loss.item())       \n",
        "          if (epoch+1) % 5 == 0 or epoch == 0: # save the model every _ epoch\n",
        "              torch.save(self.model, 'model/model{save_model_time}/net_{epoch}.pkl'.format(save_model_time=save_model_time,epoch=int((epoch+1)/5)))\n",
        "              torch.save(self.model.state_dict(), 'model/model{save_model_time}/net_params_{epoch}.pkl'.format(save_model_time=save_model_time,epoch=int((epoch+1)/5)))\n",
        "          \n",
        "          self.test(epoch) # run through the validation set\n",
        "\n",
        "    def test(self,epoch):\n",
        "            \n",
        "      self.model.eval()    # puts model in eval mode\n",
        "      self.test_loss = []\n",
        "      self.test_accuracy = []\n",
        "\n",
        "      for i, (data, labels) in enumerate(self.valid_loader):\n",
        "          \n",
        "          data, labels = data.to(self.device),labels.to(self.device)\n",
        "          # pass data through network\n",
        "          # turn off gradient calculation to speed up calcs and reduce memory\n",
        "          with torch.no_grad():\n",
        "              outputs = self.model(data)\n",
        "          # make our predictions and update our loss info\n",
        "          labels = labels.unsqueeze(1)\n",
        "          loss = self.criterion(outputs, labels)\n",
        "          self.test_loss.append(loss.item())\n",
        "      \n",
        "      test_loss.append(np.mean(self.test_loss))\n",
        "      train_loss.append(np.mean(self.tr_loss))    \n",
        "      bestmodel(self.model,save_model_time,np.mean(self.test_loss)) # find best model\n",
        "      print('epoch: {}, train loss: {}, test loss: {}'.format( \n",
        "      epoch+1, np.mean(self.tr_loss), np.mean(self.test_loss)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p695YAqric1T"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRiQ3g1fieC3"
      },
      "source": [
        "train_X, train_y = shuffle(train_X, train_y, random_state=0) \n",
        "train_X_sub = train_X[:2000]\n",
        "train_y_sub = train_y[:2000]\n",
        "sub_dataset = MyDataset(train_X_sub, train_y_sub)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL_Xxe3cihqx"
      },
      "source": [
        "def get_list_con(model):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    pred, true = [], []\n",
        "    for i, (data, labels) in enumerate(test_loader):\n",
        "      data, labels = data.to(device),labels.to(device)\n",
        "    # pass data through network\n",
        "    # turn off gradient calculation to speed up calcs and reduce memory\n",
        "      with torch.no_grad():\n",
        "          outputs = model(data)\n",
        "    # make our predictions and update our loss info\n",
        "      predicted = []\n",
        "      for o in outputs.tolist():\n",
        "        predicted.append(o[0])\n",
        "      pred.extend(predicted)\n",
        "      true.extend(labels.tolist())\n",
        "    return true, pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WIAY5EmisD_"
      },
      "source": [
        "### AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIISQ19Kiowg"
      },
      "source": [
        "def getAUC(model):\n",
        "    labels, predicts = get_list_cat(model)\n",
        "    score = metrics.roc_auc_score(labels, predicts, average='weighted')\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StwLshCMixwu"
      },
      "source": [
        "### Pearson R"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P5skco4iqVp"
      },
      "source": [
        "def getR(model):\n",
        "    labels, predicts = get_list_con(model)\n",
        "    corr, _ = stats.pearsonr(labels, predicts)\n",
        "    return corr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-JPjltdiziI"
      },
      "source": [
        "### Plot Train Verse Test Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXqeSWbQi1wQ"
      },
      "source": [
        "def pltloss(train_loss, test_loss, epoch):\n",
        "    epochs = [i for i in range(epoch)]\n",
        "    fig = plt.figure()\n",
        "    plt.plot(epochs, train_loss, 'g', label='Training loss')\n",
        "    plt.plot(epochs, test_loss, 'b', label='Testing loss')\n",
        "    plt.title('Training and Testing Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWLOcVopi3n7"
      },
      "source": [
        "### Plot R"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XChf5ZJWi5Ie"
      },
      "source": [
        "def pltR(r, epoch):\n",
        "    epochs = [i for i in range(epoch+1)][::5][1:]\n",
        "    fig = plt.figure()\n",
        "    plt.plot(epochs, r, 'g', label='Pearson R')\n",
        "    plt.title('R Score Over Time')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('R')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhGNPuIVi683"
      },
      "source": [
        "### Plot Predicated Verse Label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpw1m71_i8uT"
      },
      "source": [
        "def plotcomp(model):\n",
        "    labels, predicts = get_list_con(model)\n",
        "    idx_list = [i for i in range(len(labels))]\n",
        "    idx_sele = random.sample(idx_list, 50)\n",
        "    fig = plt.figure()\n",
        "    label_sele, pred_sele = [], []\n",
        "    for i in idx_sele:\n",
        "      label_sele.append(labels[i])\n",
        "      pred_sele.append(predicts[i])\n",
        "    plt.scatter(pred_sele, label_sele, c='b', marker='+')\n",
        "    plt.plot([0, max(pred_sele)], [0, max(label_sele)], color = 'black', linewidth = 1)\n",
        "    plt.title('Actual Values vs Predicated Values')\n",
        "    plt.xlabel('Predicated Values')\n",
        "    plt.ylabel('Actual Values')\n",
        "    plt.xlim(0, max(pred_sele))\n",
        "    plt.ylim(0, max(label_sele))\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iCWZtFvjKEK"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD253ODdjLgX"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        \"\"\"\n",
        "        init convolution and activation layers\n",
        "        Args:\n",
        "        x: (Nx1x2004)\n",
        "        class: \n",
        "\n",
        "        \"\"\"\n",
        "        super(CNN, self).__init__() \n",
        "        \n",
        "        self.conv1 = torch.nn.Conv1d(input_size[0], 32, 3)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.conv2 = torch.nn.Conv1d(32, 64, 3)\n",
        "        self.pool = torch.nn.MaxPool1d(4)\n",
        "        self.fc1 = torch.nn.Linear(2304, num_classes)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward function describes how input tensor is transformed to output tensor\n",
        "        Args:\n",
        "            \n",
        "        \"\"\"\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        # print(x.size())\n",
        "        # assert 0\n",
        "        x = self.fc1(x)\n",
        "        x = self.sig(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1UrEL0ljN3a"
      },
      "source": [
        "cnn = CNN(train_X.shape[1:], classes)\n",
        "cnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBW2RaxFjQkq"
      },
      "source": [
        "opts = {\n",
        "    'lr': 5e-4,\n",
        "    'epochs': 50,\n",
        "    'batch_size': 100,\n",
        "    'loss_fxn': 'c'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP9qxmghjQ7z"
      },
      "source": [
        "test_loss, train_loss = [], []\n",
        "CNNTrainer = TrainHelper(model = cnn,\n",
        "                      train_set = train_dataset,\n",
        "                      test_set = valid_dataset, opts = opts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWBx50aNjSLA"
      },
      "source": [
        "CNNTrainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2aIZkCijXDr"
      },
      "source": [
        "### Check for Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxZGR4JhjY3W"
      },
      "source": [
        "r_list = []\n",
        "for num in range(opts['epochs']//5):\n",
        "  model.load_state_dict(torch.load('model/model'+save_model_time+'/net_params_'+str(num)+'.pkl'))\n",
        "  model.cuda()\n",
        "  r_list.append(getR(cnn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT5d0wkFjZbK"
      },
      "source": [
        "pltloss(train_loss, test_loss, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7BcOx7vjcA9"
      },
      "source": [
        "pltR(r_list, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYPZvLRCjeaF"
      },
      "source": [
        "plotcomp(cnn)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}