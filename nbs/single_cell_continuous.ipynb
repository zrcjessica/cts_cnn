{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "single_cell_continuous.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9aIRaaghtOe"
      },
      "source": [
        "## Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwoRZsWohI59"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#from pytorch_transformers import BertModel, BertTokenizer, BertConfig, WarmupLinearSchedule \n",
        "import re\n",
        "import pandas as pd \n",
        "import json\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "import pickle\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import f1_score, recall_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "from scipy import stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVcqZRjDhr2B"
      },
      "source": [
        "from tqdm import tqdm_notebook, trange\n",
        "\n",
        "def seed_everything(seed = 42): \n",
        "  random.seed(seed) \n",
        "  os.environ['PYTHONHASHSEED'] = str(seed) \n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed) \n",
        "  torch.cuda.manual_seed(seed) \n",
        "  torch.backends.cudnn.deterministic = True\n",
        "# For reproducible results\n",
        "seed_everything()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC_LhMbUhwQz"
      },
      "source": [
        "import matplotlib as mpl\n",
        "mpl.style.use('seaborn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1K6fXLehyQG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEbbi9A1hzWh"
      },
      "source": [
        "%cd /content/gdrive/My Drive/seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGOw2CTYh45K"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPDF3xLYh0j3"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.data = X\n",
        "        self.target = Y\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncoT478kyMm8"
      },
      "source": [
        "%ls data/log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByZDT2mwh6F4"
      },
      "source": [
        "npzfile = np.load('data/log/Astrocytes.npz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb7CPf8DiCEY"
      },
      "source": [
        "X, y = npzfile['arr_0'], npzfile['arr_1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2kzVWMWiDI_"
      },
      "source": [
        "subX, subY = shuffle(X, y, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AP5Tw3ak3vs"
      },
      "source": [
        "len(subY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e-RevIdiFM7"
      },
      "source": [
        "testX = subX[int(len(subY)*0.8):]\n",
        "testY = subY[int(len(subY)*0.8):]\n",
        "validX = subX[int(len(subY)*0.6):int(len(subY)*0.8)]\n",
        "validY = subY[int(len(subY)*0.6):int(len(subY)*0.8)]\n",
        "trainX = subX[:int(len(subY)*0.6)]\n",
        "trainY = subY[:int(len(subY)*0.6)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCCN-ybriJJ3"
      },
      "source": [
        "### Convert to Torch Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfnxuDCbiLMH"
      },
      "source": [
        "train_X = torch.from_numpy(trainX)\n",
        "train_y = torch.from_numpy(trainY)\n",
        "valid_X  = torch.from_numpy(validX)\n",
        "valid_y = torch.from_numpy(validY)\n",
        "test_X = torch.from_numpy(testX)\n",
        "test_y = torch.from_numpy(testY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB79nKP-iMPH"
      },
      "source": [
        "train_dataset = MyDataset(train_X, train_y)\n",
        "valid_dataset = MyDataset(valid_X, valid_y)\n",
        "test_dataset = MyDataset(test_X, test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZdT2YjkiPGU"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNGCp8RxiPWy"
      },
      "source": [
        "def bestmodel(model_name,save_model_time,valid_loss):\n",
        "    bestloss = 10000\n",
        "    if valid_loss < bestloss :\n",
        "        bestloss = valid_loss\n",
        "        torch.save(model_name, 'model/model{save_model_time}/bestmodel.pkl'.format(save_model_time=save_model_time))\n",
        "        torch.save(model_name.state_dict(), 'model/model{save_model_time}/net_params_bestmodel.pkl'.format(save_model_time=save_model_time))\n",
        "    return True  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIRC3Vy-iUsm"
      },
      "source": [
        "## Training and Validating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFW99-cGiVAk"
      },
      "source": [
        "save_model_time = '0'\n",
        "mkpath = 'model/model%s'% save_model_time\n",
        "# os.makedirs(mkpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDWXRSHbiXEJ"
      },
      "source": [
        "class TrainHelper():\n",
        "    '''\n",
        "    Helper class that makes it a bit easier and cleaner to define the training routine\n",
        "    \n",
        "    '''\n",
        "\n",
        "    def __init__(self,model,train_set,test_set,opts):\n",
        "      self.model = model  # neural net\n",
        "\n",
        "      # device agnostic code snippet\n",
        "      self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "      self.model.to(self.device)\n",
        "\n",
        "      self.epochs = opts['epochs']\n",
        "      self.optimizer = torch.optim.Adam(model.parameters(), opts['lr']) # optimizer method for gradient descent\n",
        "      #self.optimizer = torch.optim.SGD(model.parameters(), opts['lr'])\n",
        "      self.criterion = torch.nn.MSELoss()\n",
        "      self.train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                                      batch_size=opts['batch_size'],\n",
        "                                                      shuffle=True)\n",
        "      self.valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
        "                                                      batch_size=opts['batch_size'],\n",
        "                                                      shuffle=True)\n",
        "    def train(self):\n",
        "      self.model.train() # put model in training mode\n",
        "      for epoch in range(self.epochs):\n",
        "          self.tr_loss = []\n",
        "          for i, (data,labels) in tqdm_notebook(enumerate(self.train_loader),\n",
        "                                                  total = len(self.train_loader)):\n",
        "\n",
        "              data, labels = data.to(self.device),labels.to(self.device)\n",
        "              self.optimizer.zero_grad()  \n",
        "              outputs = self.model(data)\n",
        "              labels = labels.unsqueeze(1)\n",
        "              loss = self.criterion(outputs.float(), labels.float())\n",
        "              loss.backward()                        \n",
        "              self.optimizer.step()                  \n",
        "              self.tr_loss.append(loss.item())       \n",
        "          if (epoch+1) % 5 == 0 or epoch == 0: # save the model every _ epoch\n",
        "              torch.save(self.model, 'model/model{save_model_time}/net_{epoch}.pkl'.format(save_model_time=save_model_time,epoch=int((epoch+1)/5)))\n",
        "              torch.save(self.model.state_dict(), 'model/model{save_model_time}/net_params_{epoch}.pkl'.format(save_model_time=save_model_time,epoch=int((epoch+1)/5)))\n",
        "          \n",
        "          self.test(epoch) # run through the validation set\n",
        "\n",
        "    def test(self,epoch):\n",
        "            \n",
        "      self.model.eval()    # puts model in eval mode\n",
        "      self.test_loss = []\n",
        "      self.test_accuracy = []\n",
        "\n",
        "      for i, (data, labels) in enumerate(self.valid_loader):\n",
        "          \n",
        "          data, labels = data.to(self.device),labels.to(self.device)\n",
        "          # pass data through network\n",
        "          # turn off gradient calculation to speed up calcs and reduce memory\n",
        "          with torch.no_grad():\n",
        "              outputs = self.model(data)\n",
        "          # make our predictions and update our loss info\n",
        "          labels = labels.unsqueeze(1)\n",
        "          loss = self.criterion(outputs, labels)\n",
        "          self.test_loss.append(loss.item())\n",
        "      \n",
        "      test_loss.append(np.mean(self.test_loss))\n",
        "      train_loss.append(np.mean(self.tr_loss))    \n",
        "      bestmodel(self.model,save_model_time,np.mean(self.test_loss)) # find best model\n",
        "      print('epoch: {}, train loss: {}, test loss: {}'.format( \n",
        "      epoch+1, np.mean(self.tr_loss), np.mean(self.test_loss)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p695YAqric1T"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRiQ3g1fieC3"
      },
      "source": [
        "train_X, train_y = shuffle(train_X, train_y, random_state=0) \n",
        "train_X_sub = train_X[:2000]\n",
        "train_y_sub = train_y[:2000]\n",
        "sub_dataset = MyDataset(train_X_sub, train_y_sub)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=True)\n",
        "sub_loader = torch.utils.data.DataLoader(sub_dataset, batch_size=100, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL_Xxe3cihqx"
      },
      "source": [
        "def get_list_con(model, loader):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    pred, true = [], []\n",
        "    for i, (data, labels) in enumerate(loader):\n",
        "      data, labels = data.to(device),labels.to(device)\n",
        "    # pass data through network\n",
        "    # turn off gradient calculation to speed up calcs and reduce memory\n",
        "      with torch.no_grad():\n",
        "          outputs = model(data)\n",
        "    # make our predictions and update our loss info\n",
        "      predicted = []\n",
        "      for o in outputs.tolist():\n",
        "        predicted.append(o[0])\n",
        "      pred.extend(predicted)\n",
        "      true.extend(labels.tolist())\n",
        "    return true, pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WIAY5EmisD_"
      },
      "source": [
        "### AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIISQ19Kiowg"
      },
      "source": [
        "def getAUC(model):\n",
        "    labels_tr, predicts_tr = get_list_cat(model, sub_loader)\n",
        "    score_tr = metrics.roc_auc_score(labels_tr, predicts_tr, average='weighted')\n",
        "    labels_ts, predicts_ts = get_list_cat(model, test_loader)\n",
        "    score_ts = metrics.roc_auc_score(labels_ts, predicts_ts, average='weighted')\n",
        "    return score_tr, score_ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqWn5iDCPZRT"
      },
      "source": [
        "### AUPRC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ox757OrPbKl"
      },
      "source": [
        "def getAUPRC(model):\n",
        "    labels, predicts = get_list_con(model)\n",
        "    auprc = average_precision_score(labels, predicts)\n",
        "    return auprc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StwLshCMixwu"
      },
      "source": [
        "### Pearson R"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P5skco4iqVp"
      },
      "source": [
        "def getR(model):\n",
        "    labels_tr, predicts_tr = get_list_con(model, sub_loader)\n",
        "    corr_tr, _ = stats.pearsonr(labels_tr, predicts_tr)\n",
        "    labels_ts, predicts_ts = get_list_con(model, test_loader)\n",
        "    corr_ts, _ = stats.pearsonr(labels_ts, predicts_ts)\n",
        "    return corr_tr, corr_ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7azqoijgT2wZ"
      },
      "source": [
        "### Average Percentage Change"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QZoksiDT71x"
      },
      "source": [
        "def avgDiff(model):\n",
        "    labels, predicts = get_list_con(model, test_loader)\n",
        "    all = []\n",
        "    for i, y in enumerate(labels):\n",
        "      div = y\n",
        "      if y == 0:\n",
        "        div = 0.0000000001\n",
        "      all.append((predicts[i]-y)/div)\n",
        "    all = np.array(all)\n",
        "    all_abs = np.absolute(all)\n",
        "    return np.mean(all_abs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-JPjltdiziI"
      },
      "source": [
        "### Plot Train Verse Test Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXqeSWbQi1wQ"
      },
      "source": [
        "def pltloss(train_loss, test_loss, epoch):\n",
        "    epochs = [i for i in range(epoch)]\n",
        "    fig = plt.figure()\n",
        "    plt.plot(epochs, train_loss, 'g', label='Training loss')\n",
        "    plt.plot(epochs, test_loss, 'b', label='Testing loss')\n",
        "    plt.title('Training and Testing Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWLOcVopi3n7"
      },
      "source": [
        "### Plot R"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XChf5ZJWi5Ie"
      },
      "source": [
        "def pltR(r_tr, r_ts, epoch):\n",
        "    epochs = [i for i in range(epoch+1)][::5][1:]\n",
        "    fig = plt.figure()\n",
        "    plt.plot(epochs, r_tr, 'g', label='Pearson R for Training')\n",
        "    plt.plot(epochs, r_ts, 'b', label='Pearson R for Testing')\n",
        "    plt.title('R Score Over Time')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('R')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhGNPuIVi683"
      },
      "source": [
        "### Plot Predicated Verse Label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpw1m71_i8uT"
      },
      "source": [
        "def plotcomp(model, loader):\n",
        "    labels, predicts = get_list_con(model, loader)\n",
        "    # idx_list = [i for i in range(len(labels))]\n",
        "    # idx_sele = random.sample(idx_list, 50)\n",
        "    fig = plt.figure()\n",
        "    # label_sele, pred_sele = [], []\n",
        "    # for i in idx_sele:\n",
        "    #   label_sele.append(labels[i])\n",
        "    #   pred_sele.append(predicts[i])\n",
        "    # plt.scatter(pred_sele, label_sele, c='b', marker='+')\n",
        "    plt.scatter(labels, predicts)\n",
        "    #l = max(max(pred_sele), max(label_sele))\n",
        "    l = max(max(predicts), max(labels))\n",
        "    s = min(min(predicts), min(labels))\n",
        "    plt.plot([s, l], [s, l], color = 'black', linewidth = 1)\n",
        "    plt.title('Actual Values vs Predicated Values')\n",
        "    plt.xlabel('Predicated Values')\n",
        "    plt.ylabel('Actual Values')\n",
        "    plt.xlim(s, l)\n",
        "    plt.ylim(s, l)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iCWZtFvjKEK"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJsWCZ4fJqGk"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD253ODdjLgX"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        \"\"\"\n",
        "        init convolution and activation layers\n",
        "        Args:\n",
        "        x: (Nx1x2004)\n",
        "        class: \n",
        "\n",
        "        \"\"\"\n",
        "        super(CNN, self).__init__() \n",
        "        \n",
        "        self.conv1 = torch.nn.Conv1d(input_size[0], 128, 2)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.conv2 = torch.nn.Conv1d(128, 64, 2)\n",
        "        self.pool = torch.nn.AvgPool1d(4)\n",
        "        self.fc1 = torch.nn.Linear(2368, 2368)\n",
        "        self.fc2 = torch.nn.Linear(2368, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward function describes how input tensor is transformed to output tensor\n",
        "        Args:\n",
        "            \n",
        "        \"\"\"\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1UrEL0ljN3a"
      },
      "source": [
        "cnn = CNN(train_X.shape[1:])\n",
        "cnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBW2RaxFjQkq"
      },
      "source": [
        "opts = {\n",
        "    'lr': 1e-4,\n",
        "    'epochs': 50,\n",
        "    'batch_size': 100,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP9qxmghjQ7z"
      },
      "source": [
        "test_loss, train_loss = [], []\n",
        "CNNTrainer = TrainHelper(model = cnn,\n",
        "                      train_set = train_dataset,\n",
        "                      test_set = valid_dataset, opts = opts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWBx50aNjSLA"
      },
      "source": [
        "CNNTrainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2aIZkCijXDr"
      },
      "source": [
        "#### Check for Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lxZGR4JhjY3W"
      },
      "source": [
        "r_list = []\n",
        "for num in range(opts['epochs']//5):\n",
        "  cnn.load_state_dict(torch.load('model/model'+save_model_time+'/net_params_'+str(num)+'.pkl'))\n",
        "  cnn.cuda()\n",
        "  r_list.append(getR(cnn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lT5d0wkFjZbK"
      },
      "source": [
        "pltloss(train_loss, test_loss, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7BcOx7vjcA9"
      },
      "source": [
        "pltR(r_list, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYPZvLRCjeaF"
      },
      "source": [
        "plotcomp(cnn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nweE-Te-AZoV"
      },
      "source": [
        "### Basenji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCVYoVOYPtI7"
      },
      "source": [
        "https://github.com/calico/basenji/blob/master/manuscripts/genome_research2018/params.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R0AEXiDAbL8"
      },
      "source": [
        "class Besenji(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        \"\"\"\n",
        "        init convolution and activation layers\n",
        "        Args:\n",
        "        class: \n",
        "\n",
        "        \"\"\"\n",
        "        super(Besenji, self).__init__() \n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.05)\n",
        "        self.dropout1 = nn.Dropout(p=0.1)\n",
        "        self.batch6 = nn.BatchNorm1d(108)\n",
        "\n",
        "        self.conv1 = nn.Conv1d(input_size[0], 312, kernel_size=22)\n",
        "        self.batch1 = nn.BatchNorm1d(312)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(312, 368, kernel_size=1)\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        self.batch2 = nn.BatchNorm1d(368)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(368, 435, kernel_size=6)\n",
        "        self.pool3 = nn.MaxPool1d(4)\n",
        "        self.batch3 = nn.BatchNorm1d(435)\n",
        "\n",
        "        self.conv4 = nn.Conv1d(435, 607, kernel_size=6)\n",
        "        self.pool4 = nn.MaxPool1d(4)\n",
        "        self.batch4 = nn.BatchNorm1d(607)\n",
        "        \n",
        "        self.conv5 = nn.Conv1d(607, 717, kernel_size=3)\n",
        "        self.batch5 = nn.BatchNorm1d(717)\n",
        "\n",
        "        self.conv6 = nn.Conv1d(717, 108, kernel_size=3, dilation=2)\n",
        "\n",
        "        self.conv7 = nn.Conv1d(108, 108, kernel_size=3, dilation=4)\n",
        "\n",
        "        self.conv8 = nn.Conv1d(108, 108, kernel_size=3, dilation=8)\n",
        "\n",
        "        self.conv9 = nn.Conv1d(108, 108, kernel_size=3, dilation=16)\n",
        "        \n",
        "        self.conv10 = nn.Conv1d(108, 108, kernel_size=3, dilation=32)\n",
        "\n",
        "        self.conv11 = nn.Conv1d(108, 108, kernel_size=3, dilation=64)\n",
        "\n",
        "        self.conv12 = nn.Conv1d(108, 1365, kernel_size=1)\n",
        "        self.batch12 = nn.BatchNorm1d(1365)\n",
        "\n",
        "        self.conv13 = nn.Conv1d(1365, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch1(self.conv1(x))\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.batch2(self.conv2(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.batch3(self.conv3(x)))\n",
        "        x = self.pool3(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.batch4(self.conv4(x)))\n",
        "        x = self.pool4(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.relu(self.batch5(self.conv5(x)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.batch6(self.conv6(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.relu(self.batch6(self.conv7(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.relu(self.batch6(self.conv8(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.relu(self.batch6(self.conv9(x)))\n",
        "        x = self.dropout1(x)\n",
        "        \n",
        "        x = self.relu(self.batch6(self.conv10(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.relu(self.batch6(self.conv11(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.relu(self.batch12(self.conv12(x)))\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.conv13(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huRCjHnNyiwp"
      },
      "source": [
        "basenji = Besenji(train_X.shape[1:])\n",
        "basenji"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW1OpyB9y8Oe"
      },
      "source": [
        "opts = {\n",
        "    'lr': 1e-4,\n",
        "    'epochs': 50,\n",
        "    'batch_size': 100,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HYlU3yxy-KF"
      },
      "source": [
        "test_loss, train_loss = [], []\n",
        "BasenjiTrainer = TrainHelper(model = basenji,\n",
        "                      train_set = train_dataset,\n",
        "                      test_set = valid_dataset, opts = opts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFUbd7k_zEIo"
      },
      "source": [
        "BasenjiTrainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNsR_mYZI9z0"
      },
      "source": [
        "### VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXAF6ZvMI-24"
      },
      "source": [
        "class VGG16(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(VGG16, self).__init__()\n",
        "        self.conv1_1 = nn.Conv1d(input_size[0], 64, kernel_size=3, padding=1)\n",
        "        self.conv1_2 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
        "\n",
        "        self.conv2_1 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv2_2 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "\n",
        "        self.conv3_1 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv3_2 = nn.Conv1d(256, 256, kernel_size=3, padding=1)\n",
        "        self.conv3_3 = nn.Conv1d(256, 256, kernel_size=3, padding=1)\n",
        "\n",
        "        self.conv4_1 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n",
        "        self.conv4_2 = nn.Conv1d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv4_3 = nn.Conv1d(512, 512, kernel_size=3, padding=1)\n",
        "\n",
        "        self.conv5_1 = nn.Conv1d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv5_2 = nn.Conv1d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv5_3 = nn.Conv1d(512, 512, kernel_size=3, padding=1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        # max pooling (kernel_size, stride)\n",
        "        self.pool = nn.MaxPool1d(2, 2)\n",
        "\n",
        "        # fully conected layers\n",
        "        self.fc6 = nn.Linear(512*18, 1000)\n",
        "        # self.fc6 = nn.Linear(512*7, 1000)\n",
        "        self.fc7 = nn.Linear(1000, 100)\n",
        "        self.fc8 = nn.Linear(100, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv1_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.conv2_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.conv3_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3_3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.conv4_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv4_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv4_3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.relu(self.conv5_1(x))\n",
        "        x = self.relu(self.conv5_2(x))\n",
        "        x = self.relu(self.conv5_3(x))\n",
        "        x = self.pool(x)\n",
        "        # print(x.size())\n",
        "        x = torch.flatten(x, 1)\n",
        "        # print(x.size())\n",
        "        # assert 0\n",
        "        x = self.fc6(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc7(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1IrfLc5JB9V"
      },
      "source": [
        "vgg = VGG16(train_X.shape[1:])\n",
        "vgg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXpvPZfxJZEv"
      },
      "source": [
        "opts = {\n",
        "    'lr': 1e-4,\n",
        "    'epochs': 50,\n",
        "    'batch_size': 100,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz11EKpYJbyj"
      },
      "source": [
        "test_loss, train_loss = [], []\n",
        "VGGTrainer = TrainHelper(model = vgg,\n",
        "                      train_set = train_dataset,\n",
        "                      test_set = valid_dataset, opts = opts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bePHehgIJheF"
      },
      "source": [
        "VGGTrainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xnjXE4FJkqr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZBEnge2JuYD"
      },
      "source": [
        "#### Check for Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9cnPwATJvwO"
      },
      "source": [
        "r_list_ts = []\n",
        "r_list_tr = []\n",
        "for num in range(opts['epochs']//5):\n",
        "  vgg.load_state_dict(torch.load('model/model'+save_model_time+'/net_params_'+str(num)+'.pkl'))\n",
        "  vgg.cuda()\n",
        "  tr, ts = getR(vgg)\n",
        "  r_list_ts.append(ts)\n",
        "  r_list_tr.append(tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nsbd3iDPQxr6"
      },
      "source": [
        "vgg.load_state_dict(torch.load('model/model'+save_model_time+'/net_params_8.pkl'))\n",
        "getR(vgg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVRj4BQ6bOqV"
      },
      "source": [
        "avgDiff(vgg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__RVV7rkJ1SO"
      },
      "source": [
        "pltloss(train_loss, test_loss, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYI2AZxVJ4Mh"
      },
      "source": [
        "pltR(r_list_tr, r_list_ts, opts['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2JQEsp-PybT"
      },
      "source": [
        "plotcomp(vgg,sub_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gutvXcKVLen5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}